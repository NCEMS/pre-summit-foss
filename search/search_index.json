{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-ncems-pre-summit-foundational-open-science-skills-foss-training","title":"Welcome to NCEMS Pre Summit Foundational Open Science Skills (FOSS) Training!","text":""},{"location":"#workshop-summary","title":"Workshop Summary","text":"<p>NCEMS presents Foundational Open Science Skills (FOSS) as a roadmap to guide your computational research and level up your teaching, collaboration, proposal writing, and publishing. </p> <p>FOSS offers a hands-on learning resource to build a solid Open Science foundation for your research and educational projects in a supportive atmosphere with peers and project mentors. </p> <p>The workshop focuses on introducing you to a host of software tools to help manage your data and make your science open, reproducible, and scaleable. Please see the Schedule for the list of lessons and content covered throughout the workshop. </p>"},{"location":"#workshop-structure","title":"Workshop Structure","text":"<p>Synchronously, we will meet each week virtually for 1.5 hours to discuss and have hands-on activities with our instructors. The workshop content is always available for you to read through to develop your own project-based ideas for strengthening your Open Science skills. </p> <p>Much of the content interconnects from week to week and many of the skills and approaches we discuss relate to each other. However, students should be able to derive significant value from attending single sessions. </p> <p>Our ultimate goal in this workshop is for you to \"level up\" one or more of those philosophies/approaches/skills. </p>"},{"location":"#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>Proficiently organize your lab, external and internal communications, and teach and conduct research with open source software</li> <li>Ability to scale out computations from laptop to the cloud and High Performance Computing/High Throughput Computing systems</li> <li>Skillfully manage your research data through the data lifecycle </li> <li>Join a larger community of Open Science practitioners</li> <li>Be an Advocate for Open Science in your professional circles and communities</li> </ul> <p>By working through an example project relevant to your interests, you will practice open science skills using CyVerse, GitHub, R or Python, and other resources. At the end of the course, you and your team will present a plan for how to integrate open science into your research, lab, or other areas of your choosing.</p> <p>Funding and Citations:</p> <p>NCEMS is funded by the National Science Foundation under Award Number  </p> <p>CyVerse is funded by the Arizona Board of Regents and the US National Science Foundation under Award Numbers: </p> <p> </p> <p>The CyVerse Zenodo Community has published, citable versions of CyVerse Learning materials: </p> <p></p> <p>Please cite CyVerse appropriately when you make use of our resources; see CyVerse citation policy.</p> <p> </p>"},{"location":"01_intro_open_sci/","title":"Introduction to Open Science","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Explain what Open Science is</li> <li>Explain the components of Open Science</li> <li>Describe the behaviors of Open Science</li> <li>Explain why Open Science matters in education, research, and society</li> <li>Understand the advantages and the challenges to Open Science</li> </ul> <p> </p> <p>Instant Feedback: </p> <p>HackMD: https://hackmd.io/tLnlwjjTSoGG8U2yPHWQJw </p>"},{"location":"01_intro_open_sci/#what-is-open-science","title":"What is Open Science?","text":"<p>\"Open Science is transparent and accessible knowledge that is shared and developed through collaborative networks\"</p> <p>-Vincente-Saez &amp; Martinez-Fuentes 2018</p> <p> </p> <p>  The Research Life Cycle from Open Science Framework</p> <p> </p> <p>Definitions of Open Science</p> <p>\"Open Science is defined as an inclusive construct that combines various movements and practices aiming to make multilingual scientific knowledge openly  available,  accessible  and  reusable  for  everyone,  to  increase  scientific  collaborations  and  sharing of information for the benefits of science and society, and to open the processes of scientific knowledge creation, evaluation and communication to societal actors beyond the traditional scientific community.\" - UNESCO Definition</p> <ul> <li>UNESCO's Recommendation on Open Science</li> </ul> <p>\"Open Science is the movement to make scientific research (including publications, data, physical samples, and software) and its dissemination accessible to all levels of society, amateur or professional...\"   Wikipedia definition</p> <p></p>"},{"location":"01_intro_open_sci/#foundational-open-science-skills","title":"Foundational Open Science Skills","text":"<p>The original CyVerse FOSS workshop is designed to:</p> <p>1. Building a culture of scientists eager to share research materials - such as data, code, methods, documentation, and early results - with colleagues and society at large, in addition to traditional publications </p> <p> </p> <p>2. Mastery of digital tools to create reproducible science that others can build upon</p> <p> </p> <p>3. Understanding the push towards increased transparency and accountability for those practicing science (ie., compliance)</p> <p> </p>  Open Science Word Cloud by Pownall et al. 2023 <p> </p> What is Open Science | The Royal Society <p> </p>"},{"location":"01_intro_open_sci/#2023-the-year-of-open-science","title":"2023: the Year of Open Science","text":"<p>The White House, joined by 10 federal agencies, and a coalition of more than 85 universities, declared 2023 the Year of Open Science as a way to bring awareness to the benefits of Open Science and to steer the scientitic community towards its adoption. </p> <p>NASA leads a prominent program called Transform to Open Science which includes an online class on Open Science. </p> <p>  NASA Transform to Open Science (TOPS) </p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#6-pillars-of-open-science","title":"6 Pillars of Open Science","text":"<p> Open Access Publications</p> <p> Open Data</p> <p> Open Educational Resources</p> <p> Open Methodology</p> <p> Open Peer Review</p> <p> Open Source Software</p> Wait, how many pillars  of Open Science Are There Really? <p>The number can be from 4  to 8 </p> <p> </p>"},{"location":"01_intro_open_sci/#open-access-publications","title":"Open Access Publications","text":"<p>Definition</p> <p>\"Open access is a publishing model for scholarly communication that makes research information available to readers at no cost, as opposed to the traditional subscription model in which readers have access to scholarly information by paying a subscription (usually via libraries).\" -- OpenAccess.nl</p> <p> </p> <p>Open Access Journal Examples</p> <p>Major publishers have provided access points for publishing your work </p> <ul> <li>AAAS Science</li> <li>Nature</li> <li>American Geophysical Union</li> <li>Commonwealth Scientific and Industrial Research Organisation (CSIRO)</li> <li>Open Research Europe</li> <li>PLOS</li> <li>MDPI</li> <li>Ecosphere</li> </ul> <p>Directory of Open Access Journals</p> <p> </p>"},{"location":"01_intro_open_sci/#types-of-publishing-business-models","title":"Types of Publishing Business Models:","text":"<ol> <li> <p>Subscription model - the author pays a smaller fee (or no fee) for the article to be published. The publisher then sells subscription access to the article (usually to institutes of higher education).</p> </li> <li> <p>Open Access model - The author pays a larger fee to make the article freely available to anyone through a Creative Commons license. </p> <ul> <li>Open Access publishing in Nature costs $12,290!</li> <li>Open Access publising in PlosOne costs $2,290</li> </ul> </li> </ol> <p> </p>"},{"location":"01_intro_open_sci/#research-article-versions","title":"Research Article Versions","text":"<ol> <li> <p>Preprint - In academic publishing, a preprint is a version of scholary paper that precedes formal peer-review and publication in a scientific journal. The preprint may be available, often as a non-typeset version available for free online. </p> Pre-print Services <ul> <li>ASAPbio Pre-Print Server List - ASAPbio is a scientist-driven non-profit promoting transparency and innovation comprehensive list of pre-print servers inthe field of life science communication.</li> <li>ESSOar - Earth and Space Science Open Archive hosted by the American Geophysical Union.</li> <li>Peer Community In (PCI) a free recommendation process of scientific preprints based on peer reviews</li> <li>OSF.io Preprints are partnered with numerous projects under the \"-rXivs\"</li> </ul> The rXivs <ul> <li> <p>AfricArXiv</p> </li> <li> <p>AgrirXiv</p> </li> <li> <p>Arabixiv</p> </li> <li> <p>arXiv - is a free distribution service and an open-access archive for 2,086,431 scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.</p> </li> <li> <p>BioHackrXiv</p> </li> <li>BioRxiv -  is an open access preprint repository for the biological sciences.</li> <li>BodorXiv</li> <li>EarthArXiv - is an open access preprint repository for the Earth sciences.</li> <li>EcsArXiv - a free preprint service for electrochemistry and solid state science and technology</li> <li>EdArXiv - for the education research community</li> <li>EngrXiv for the engineering community</li> <li>EvoEcoRxiv - is an open acccess preprint repository for Evolutionary and Ecological sciences.</li> <li>MediArXiv for Media, Film, &amp; Communication Studies</li> <li>MedRxiv - is an open access preprint repository for Medical sciences.</li> <li>PaleorXiv - is an open access preprint repository for Paleo Sciences</li> <li>PsyrXiv - is an open access preprint repository for Psychological sciences.</li> <li>SocArXiv - is an open access preprint repository for Social sciences.</li> <li>SportrXiv - is an open access preprint for Sports sciences.</li> <li>ThesisCommons - open Theses</li> </ul> </li> <li> <p>Author's accepted manuscript (AAM) - includes changes that came about during peer-review process. It is a non-typeset or formatted article. This often had an embargo period of 12-24 months</p> </li> <li> <p>Published version of record (VOR) - includes stylistic edits, online &amp; print formatting. This is the version that publishers claim ownership of with copyrights or exclusive licensing. </p> </li> </ol> <p> </p> Copyrights and Science Publishing <p>Upon completion of a peer-reviewed science paper, the author typically 1. signs over the copyright of the paper to the publisher or 2. signs an exclusive license agreement with the publisher</p> <p>For example authors that publish in Science retain their copyright but sign a 'license to pubish' agreement with AAAS</p> <p>Elsevier requires authors to sign over copyright of the article but authors retains some rights of distribution</p> <ul> <li>Elsevier summary of copyright policies</li> <li>Elsevier article sharing policy</li> <li>Wiley policy on self-archiving</li> <li>Springer Nature copyright policies</li> </ul> <p> </p>"},{"location":"01_intro_open_sci/#new-open-access-mandates-in-us","title":"New Open Access Mandates in US","text":"<p>The White House Office of Science and Technology (OSTP) has recently released a policy document known as the Nelson Memo stating that tax-payer funded research must by open access by 2026 with no embargo period. </p> <p>Authors can comply with the memo by either:</p> <ol> <li>Publishing Open Access (this usually requires higher fees)</li> <li>Distributing the Author's Accepted Manuscript (AAM) </li> </ol> <p>Read USDA's open access plan in reponse to the Nelson Memo</p> <p> </p>"},{"location":"01_intro_open_sci/#additional-info","title":"Additional Info","text":"<p>University of Arizona Libraries information on Open Access publishing including agreements with several journals to reduce or waive publishing fees. </p> <p>https://www.coalition-s.org/</p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-data","title":"Open Data","text":"<p>Definitions</p> <p>\u201cOpen data and content can be freely used, modified, and shared by anyone for any purpose\u201d - The Open Definition</p> <p>\"Open data is data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and sharealike.\" - Open Data Handbook</p> <p> Wikipedia definition</p> <p> </p> <p>Data are the foundation for any scientific endeavor. A lot of thought needs to go into how to best collect, store, analyze, curate, share, and archive data.</p> <p>  DIKW Pyramid</p> <p> </p>"},{"location":"01_intro_open_sci/#fair-principles","title":"FAIR Principles","text":"<p>In 2016, the FAIR Guiding Principles for scientific data management and stewardship were published in Scientific Data. </p> <p>Findable: Making data discoverable by the wider academic community and the public</p> <p>Accessible: Using unique identifiers, metadata and a clear use of language and access protocols</p> <p>Interoperable: Applying standards to encode and exchange data and metadata</p> <p>Reusable: Enabling the repurposing of researach outputs to maximize their research potential</p> <p> </p> <p>Reasons to Make your Data Open</p> <ul> <li>Unnecessary duplication. Duplication of research is costly for society, and places unnecessary burden on heavily researched people and populations.  </li> <li>The data underlying publications are maintained and accessible, allowing for validation of results.</li> <li>Data openness leads to more collaboration and advances research and innovation.</li> <li>Your research is more visible and has greater impact. Publications which allow access to the underlying data get more citations. Greater visibility also allows for better validation and scrutiny of findings.</li> <li>Other researchers can cite your data, which will drive up your citation number and increase your influence in your field of research.</li> <li>Storing your data in a public repository also provides you with secure and ongoing storage that may otherwise not be available to you. -Foster Open Science</li> </ul> <p> </p>"},{"location":"01_intro_open_sci/#as-open-as-possible-as-closed-as-necessary","title":"As Open as Possible, as Closed as Necessary","text":"<p>There are many circumstances where open data could be harmful:</p> <ul> <li> <p>Data on human health</p> </li> <li> <p>Location of endangered species or archaeological sites</p> </li> <li> <p>Data that individuals or groups do not want to be public</p> CARE Principles <p>The CARE Principles for Indigenous Data Governance were drafted at the International Data Week and Research Data Alliance Plenary co-hosted event \"Indigenous Data Sovereignty Principles for the Governance of Indigenous Data Workshop,\" 8 November 2018, Gaborone, Botswana.</p> <p>Collective Benefit</p> <ul> <li>C1. For inclusive development and innovation</li> <li>C2. For improved governance and citizen engagement</li> <li>C3. For equitable outcomes</li> </ul> <p>Authority to Control</p> <ul> <li>A1. Recognizing rights and interests</li> <li>A2. Data for governance</li> <li>A3. Governance of data</li> </ul> <p>Responsibility</p> <ul> <li>R1. For positive relationships</li> <li>R2. For expanding capability and capacity</li> <li>R3. For Indigenous languages and worldviews</li> </ul> <p>Ethics</p> <ul> <li>E1. For minimizing harm and maximizing benefit</li> <li>E2. For justice</li> <li>E3. For future use</li> </ul> </li> <li> <p>Data for making lethal weapons</p> TRUST Principles <p>Lin et al. 2020 The TRUST Principles for digital repositories</p> <p>Transparency</p> <ul> <li> <p>Terms of use, both for the repository and for the data holdings.</p> </li> <li> <p>Minimum digital preservation timeframe for the data holdings.</p> </li> <li> <p>Any pertinent additional features or services, for example the capacity to responsibly steward sensitive data.</p> </li> </ul> <p>Responsibility</p> <ul> <li> <p>Adhering to the designated community\u2019s metadata and curation standards, along with providing stewardship of the data holdings e.g. technical validation, documentation, quality control, authenticity protection, and long-term persistence.</p> </li> <li> <p>Providing data services e.g. portal and machine interfaces, data download or server-side processing.</p> </li> <li> <p>Managing the intellectual property rights of data producers, the protection of sensitive information resources, and the security of the system and its content.</p> </li> </ul> <p>User focus</p> <ul> <li> <p>Implementing relevant data metrics and making these available to users.</p> </li> <li> <p>Providing (or contributing to) community catalogues to facilitate data discovery.</p> </li> <li> <p>Monitoring and identifying evolving community expectations and responding as required to meet these changing needs.</p> </li> </ul> <p>Sustainability</p> <ul> <li> <p>Planning sufficiently for risk mitigation, business continuity, disaster recovery, and succession.</p> </li> <li> <p>Securing funding to enable ongoing usage and to maintain the desirable properties of the data resources that the repository has been entrusted with preserving and disseminating.</p> </li> <li> <p>Providing governance for necessary long-term preservation of data so that data resources remain discoverable, accessible, and usable in the future.</p> </li> </ul> <p>Technology</p> <ul> <li> <p>Implementing relevant and appropriate standards, tools, and technologies for data management and curation.</p> </li> <li> <p>Having plans and mechanisms in place to prevent, detect, and respond to cyber or physical security threats.</p> </li> </ul> </li> </ul> <p> </p> <p>Open vs. FAIR</p> <p>FAIR does not demand that data be open: See one definition of open: http://opendefinition.org/</p> <p>Open data does not necessarily mean it is FAIR</p> <p> </p>"},{"location":"01_intro_open_sci/#additional-info_1","title":"Additional Info","text":"<ul> <li> <p>The Ethics of Geolocated Data from UK Statistics Authority </p> </li> <li> <p>Health information US HIPAA</p> </li> <li> <p>Indigenous data sovereignty: CARE Principles for Indigenous Data Governance , Global Indigenous Data Alliance (GIDA), First Nations OCAP\u00ae (Ownership Control Access and Possession), Circumpolar Inuit Protocols for Equitable and Ethical Engagement </p> </li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-educational-resources","title":"Open Educational Resources","text":"<p>Definitions</p> <p>\"Open Educational Resources (OER) are learning, teaching and research materials in any format and medium that reside in the public domain or are under copyright that have been released under an open license, that permit no-cost access, re-use, re-purpose, adaptation and redistribution by others.\" - UNESCO</p> <p> Wikipedia definition</p> Digital Literacy Organizations <ul> <li>The Carpentries - teaches foundational coding and data science skills to researchers worldwide  </li> <li>EdX - Massively Open Online Courses (not all open) hosted through University of California Berkeley</li> <li>EveryoneOn - mission is to unlock opportunity by connecting families in underserved communities to affordable internet service and computers, and delivering digital skills trainings </li> <li>ConnectHomeUSA - is a movement to bridge the digital divide for HUD-assisted housing residents in the United States under the leadership of national nonprofit EveryoneOn</li> <li>Global Digital Literacy Council -  has dedicated more than 15 years of hard work to the creation and maintenance of worldwide standards in digital literacy</li> <li>IndigiData - training and engaging tribal undergraduate and graduate students in informatics</li> <li>National Digital Equity Center a 501c3 non-profit, is a nationally recognized organization with a mission to close the digital divide across the United States</li> <li>National Digital Inclusion Allaince - advances digital equity by supporting community programs and equipping policymakers to act</li> <li>Net Literacy</li> <li>Open Educational Resources Commons</li> <li>Project Pythia is the education working group for Pangeo and is an educational resource for the entire geoscience community</li> <li>Research Bazaar - is a worldwide festival promoting the digital literacy emerging at the centre of modern research</li> <li>TechBoomers - is an education and discovery website that provides free tutorials of popular websites and Internet-based services in a manner that is accessible to older adults and other digital technology newcomers</li> </ul> Educational Materials <ul> <li>Teach Together by Greg Wilson</li> <li>DigitalLearn</li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-methodology","title":"Open Methodology","text":"<p>Definitions</p> <p>\"An open methodology is simply one which has been described in sufficient detail to allow other researchers to repeat the work and apply it elsewhere.\" - Watson (2015)</p> <p>\"Open Methodology refers to opening up methods that are used by researchers to achieve scientific results and making them publicly available.\" - Open Science Network Austria</p> <p> </p>"},{"location":"01_intro_open_sci/#sharing-research-computer-code","title":"Sharing Research Computer Code","text":"<p>Scientists around the globe are creating computer code for scientific analysis. These are valuable contributions that need to be shared!</p> <p>Platforms like GitHub and GitLab are ideal for collaboratively developing code and sharing with the open internet. </p> <p> </p>"},{"location":"01_intro_open_sci/#publishing-your-methods-or-protocols","title":"Publishing Your Methods or Protocols","text":"Platforms for Publishing Protocols &amp; Bench Techniques <ul> <li>BioProtocol</li> <li>Current Protocols</li> <li>Gold Biotechnology Protocol list</li> <li>JoVE - Journal of Visualized Experiments</li> <li>Nature Protocols</li> <li>OpenWetWare</li> <li>Protocol Exchange</li> <li>Protocols Online</li> <li> Protocols</li> <li>SciGene</li> <li>Springer Nature Experiments</li> </ul>"},{"location":"01_intro_open_sci/#preregistration","title":"PreRegistration","text":"<p>Preregistration is detailing your research and analysis plan and submitting it to an online registry before you engage in the research. </p> <p>  PreRegistration in the Research Life Cycle</p>"},{"location":"01_intro_open_sci/#why-do-this","title":"Why Do This?","text":"<p>Preregistration makes your process more open and records the difference between your initial research plan what you end up actually doing.</p> <p>Preregistration separates hypothesis-generating  (exploratory) from hypothesis-testing (confirmatory) research. Both are important. But the same data cannot be used to generate and test a hypothesis, which can happen unintentionally and reduce the credibility of your results. </p> <p>It also helps us avoid practices like p-hacking or Hypothesizing After the Results are Known(HARKing). </p> <p></p>"},{"location":"01_intro_open_sci/#additional-info_2","title":"Additional Info","text":"<p>Read this publication by Nosek et al. 2018</p> <p>Open Science Framework Preregistration https://www.cos.io/initiatives/prereg</p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-peer-review","title":"Open Peer Review","text":"<p>Definitions</p> <p>Open peer review is an umbrella term for a number of overlapping ways that peer review models can be adapted in line with the aims of Open Science, including making reviewer and author identities open, publishing review reports and enabling greater participation in the peer review process.  </p> <p>-Ross-Hellauer et al. (2017)</p> <p></p> <p> Wikipedia's definition</p> <p> </p>"},{"location":"01_intro_open_sci/#traditional-closed-peer-review-system","title":"Traditional Closed Peer-Review System","text":"<ul> <li>Throughout and after the process, the author remains unaware of the reviewers' identities, while the reviewers know the identity of the authors. </li> <li>All communications between authors, reviewers and editors remains private </li> </ul>"},{"location":"01_intro_open_sci/#complaints-with-the-traditional-closed-peer-review-system","title":"Complaints with the Traditional Closed Peer-Review System","text":"<ul> <li>Unreliable and Inconsistent</li> <li>Delays and Expense</li> <li>Lack of Accountability and Risks of Subversion</li> <li>Social and Publication Biases</li> <li>Lack of Incentives</li> </ul> <p>Ross-Hallauer 2017</p> <p> </p>"},{"location":"01_intro_open_sci/#open-peer-review-ideas","title":"Open Peer-Review Ideas","text":"<p>  Open Peer Review Options at PLOS</p> <p> </p> <p>Defenders of the Traditional Peer-Review System</p> <p> </p> <p>Example Open Peer-Review Systems</p> <p>F1000Research An open research publishing platform that offers open peer review and rapid publication. The article from Ross-Hellauer et al. (2017) has open peer-reviews.</p> <p></p> <p>Platforms for Reviewing Preprints</p> <ul> <li>PREreview </li> <li>Sciety </li> <li>PubPeer </li> <li>ASAPbio </li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#open-source-software","title":"Open Source Software","text":"<p>Definitions</p> <p>\"Open source software is code that is designed to be publicly accessible\u2014anyone can see, modify, and distribute the code as they see fit. Open source software is developed in a decentralized and collaborative way, relying on peer review and community production.\" -  Red Hat</p> <p> Wikipedia definition</p> <p> </p> <p>Research science (and also many companies) rely on open source software to operate</p> <p> </p> <p>Open Source Software</p> <ul> <li>Linux operating system and shell</li> <li>Python </li> <li>R</li> <li>git</li> <li>Conda</li> <li>Docker</li> <li>Cyverse</li> <li>Pytorch</li> <li>Tyson's Awesome List</li> </ul> <p> </p> <p>When you create a new software, library, or package, you become its parent and guardian.</p> <p>  Image Credit: XKCD Dependency </p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#why-do-open-science","title":"WHY do Open Science?","text":"<p>A paper from Bartling &amp; Friesike (2014) posits that there are 5 main schools of thought in Open Science, which represent 5 underlying motivations:</p> <ol> <li>Democratic school: primarily concerned with making scholarly work freely available to everyone</li> <li>Pragmatic school: primarily concerned with improving the quality of scholarly work by fostering collaboration and improving critiques</li> <li>Infrastructure school: primarily focused on the platforms, tools, and services necessary to conduct efficient research, collaboration, and communication</li> <li>Public school: primarily concerned with societal impact of scholarly work, focusing on engagement with broader public via citizen science, understandable scientific communication, and less formal communication</li> <li>Measurement school: primarily concerned with the existing focus on journal publications as a means of measuring scholarly output, and focused on developing alternative measurements of scientific impact</li> </ol> <p>Government, universities, and granting agencies have embraced Open Science and are mandating some elements (e.g., the Nelson Memo)</p> <p>  In Bartling &amp; Friesike (2014) Open Science: One Term, Five Schools of Thought </p> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#discussion-questions","title":"Discussion Questions","text":"Which of the  pillars of Open Science is nearest to your own heart? <p> Open Access Publications</p> <p> Open Data</p> <p> Open Educational Resources</p> <p> Open Methodology</p> <p> Open Peer Review</p> <p> Open Source Software</p> Are any of the  pillars more important than the others? Are there any  pillars not identified that you think should be considered? What characteristics might a paper, project, lab group require to qualify as doing Open Science What are some barriers to you, your lab group, or your domain doing Open Science? What motivates you to do Open Science? Do you feel that you fall into a particular \"school\"? If so, which one, and why? Are there any motivating factors for doing Open Science that don't fit into this framework? <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#recommended-open-science-communities","title":"Recommended Open Science Communities","text":"<p> Open Scholarship Grassroots Community Networks</p>  International Open Science Networks <ul> <li>Center for Scientific Collaboration and Community Engagement (CSCCE)</li> <li>Center for Open Science (COS)</li> <li>Eclipse Science Working Group</li> <li>eLife</li> <li>NumFocus</li> <li>Open Access Working Group</li> <li>Open Research Funders Group</li> <li>Open Science Foundation</li> <li>Open Science Network</li> <li>pyOpenSci</li> <li>R OpenSci</li> <li>Research Data Alliance (RDA)</li> <li>The Turing Way</li> <li>UNESCO Global Open Science Partnership</li> <li>World Wide Web Consortium (W3C)</li> </ul>  US-based Open Science Networks <ul> <li>CI Compass - provides expertise and active support to cyberinfrastructure practitioners at USA NSF Major Facilities in order to accelerate the data lifecycle and ensure the integrity and effectiveness of the cyberinfrastructure upon which research and discovery depend.</li> <li>Earth Science Information Partners (ESIP) Federation -  is a 501\u00a9(3) nonprofit supported by NASA, NOAA, USGS and 130+ member organizations.</li> <li>Internet2 - is a community providing cloud solutions, research support, and services tailored for Research and Education. </li> <li>Minority Serving Cyberinfrastructure Consortium (MS-CC) envisions a transformational partnership to promote advanced cyberinfrastructure (CI) capabilities on the campuses of Historically Black Colleges and Universities (HBCUs), Hispanic-Serving Institutions (HSIs), Tribal Colleges and Universities (TCUs), and other Minority Serving Institutions (MSIs). </li> <li>NASA Transform to Open Science (TOPS) - coordinates efforts designed to rapidly transform agencies, organizations, and communities for Earth Science</li> <li>OpenScapes - is an approach for doing better science for future us</li> <li>The Quilt - non-profit regional research and education networks collaborate to develop, deploy and operate advanced cyberinfrastructure that enables innovation in research and education.</li> </ul>  Oceania Open Science Networks <ul> <li>New Zealand Open Research Network - New Zealand Open Research Network (NZORN) is a collection of researchers and research-associated workers in New Zealand.</li> <li>Australia &amp; New Zealand Open Research Network - ANZORN is a network of local networks distributed without Australia and New Zealand.</li> </ul> <p> </p> <p> </p>"},{"location":"01_intro_open_sci/#self-assessment","title":"Self Assessment","text":"True or False: All research papers published in the top journals, like Science and Nature, are always Open Access? Answer <p>False</p> <p>Major Research journals like Science and Nature have an \"Open Access\" option when a manuscript is accepted, but they charge an extra fee to the authors to make those papers Open Access.</p> <p>These high page costs are exclusionary to the majority of global scientists who cannot afford to front these costs out of pocket.</p> <p>This will soon change, at least in the United States. The Executive Branch of the federal government recently mandated that future federally funded research be made Open Access after 2026.</p> True or False: an article states all of the research data used in the experiments \"are available upon request from the corresponding author(s),\" meaning the data are \"Open\" Answer <p>False</p> <p>In order for research to be open, the data need to be freely available from a digital repository, like Data Dryad, Zenodo.org, or CyVerse.</p> <p>Data that are 'available upon request' do not meet the FAIR data principles. </p> Using a version control system to host the analysis code and computational notebooks, and including these in your Methods section or Supplementary Materials, is an example of an Open Methodology? Answer <p>Yes!</p> <p>Using a VCS like GitHub or GitLab is a great step towards making your research more reproducible. </p> <p>Ways to improve your open methology can include documentation of your physical bench work, and even video recordings and step-by-step guides for every part of your project.</p> You are asked to review a paper for an important journal in your field. The editor asks if you're willing to release your identity to the authors, thereby \"signing\" your review. Is this an example of \"Open Peer Review\"? Answer <p>Maybe</p> <p>There are many opinions on what 'open-review' should consist of. A reviewer signing their review and releasing their identity to the authors is a step toward a more open process. However, it is far less open than publishing the peer-review reports online next to the final published paper. </p> You read a paper where the author(s) wrote their own code and licensed as \"Open Source\" software for a specific set of scientific tasks which you want to replicate. When you visit their personal website, you find the GitHub repository does not exist (because its now private). You contact the authors asking for access, but they refuse to share it 'due to competing researchers who are seeking to steal their intellectual property\". Is the software open source? Answer <p>No</p> <p>Just because an author states they have given their software a permissive software license, does not make the software open source. </p> <p>Always make certain there is a LICENSE associated with any software you find on the internet. </p> <p>In order for the software to be open, it must follow the Open Source Initiative definition</p>"},{"location":"02_managing_data/","title":"Managing Data","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Recognize data as the foundation of open science and be able to describe the \"life cycle of data\"</li> <li>Use self-assessments to evaluate your current data management practices</li> <li>Cite tools and resources to improve your data management practices</li> <li>Know the biggest challenge to effective data management</li> </ul>"},{"location":"02_managing_data/#why-should-you-care-about-data-management","title":"Why should you care about data management?","text":"<p>Ensuring that data are effectively organized, shared, and preserved is critical to making your science impactful, efficient, and open.</p> Don't forget about Data Management <p>The biggest challenge to data management is making it an afterthought.</p> <p>Unfortunately, poor data management doesn't have a high upfront cost. You can do substantial work before realizing you are in trouble. Like a swimmer in rip current, by the time you realize you are in trouble, you may already be close to drowning.</p> <p>The solution? Make data management the first thing you consider when starting a research project. It also needs to be a policy you institute right away for your research group.</p> How would you answer? <ul> <li>If you give your data to a colleague who has not been involved with your project, would they be able to make sense of it? Would they be able to use it properly?</li> <li>If you come back to your own data in five years, will you be able to make sense of it? Will you be able to use it properly?</li> <li>When you are ready to publish a paper, is it easy to find all the correct versions of all the data you used and present them in a comprehensible manner?</li> </ul> <p>Well-managed Data Sets:</p> <ul> <li>Make life much easier for you and your collaborators</li> <li>Benefit the scientific research community by allowing others to reuse your data</li> <li>Are required by most funders and many journals</li> <li>Recent Dear Colleague letter from NSF</li> <li>NSF proposal preparation guidelines</li> </ul> <p> </p>"},{"location":"02_managing_data/#data-types","title":"Data Types","text":"<p>Different types of data require different management practices. What are some data types and sources you might use in your work? (Adapted from DMP Tool Data management general guidance)</p> <p>Data Types</p> <ul> <li>Text: field or laboratory notes, survey responses</li> <li>Numeric: tables, counts, measurements</li> <li>Audiovisual: images, sound recordings, video</li> <li>Models, computer code</li> <li>Discipline-specific: FASTA in biology, FITS in astronomy, CIF in chemistry</li> <li>Instrument-specific: equipment outputs</li> </ul> <p>Data Sources</p> <p>Observational</p> <ul> <li>Captured in real-time, typically outside the lab</li> <li>Usually irreplaceable and therefore the most important to safeguard</li> <li>Examples: Sensor readings, telemetry, survey results, images</li> </ul> <p>Experimental</p> <ul> <li>Typically generated in the lab or under controlled conditions</li> <li>Often reproducible, but can be expensive or time-consuming</li> <li>Examples: gene sequences, chromatograms, magnetic field readings</li> </ul> <p>Simulation</p> <ul> <li>Machine generated from test models</li> <li>Likely to be reproducible if the model and inputs are preserved</li> <li>Examples: climate models, economic models</li> </ul> <p>Derived / Compiled</p> <ul> <li>Generated from existing datasets</li> <li>Reproducible, but can be very expensive and time-consuming</li> <li>Examples: text and data mining, compiled database, 3D models</li> </ul> <p> </p>"},{"location":"02_managing_data/#data-self-assessment","title":"Data Self-assessment","text":"<p>Activity</p> <p>In small groups, discuss the following questions. You will be provided with a space for documenting our shared answers.</p> <p>1. What are the two or three data types that you most frequently work with?         -   Think about the sources (observational, experimental, simulated, compiled/derived)         -   Also consider the formats (tabular, sequence, database, image, etc.)</p> <p>2.  What is the scale of your data?</p> Tip <p>We often talk about the scale of data using the \"Three V's\":</p> <ul> <li>Volume: Size of the data (MBs, GBs, TBs); can also include how many files (e.g dozens of big files, or millions of small ones)</li> <li>Velocity: How quickly are these data produced and analyzed? A lot coming in a single batch infrequently, or, a constant small amount of data that must be rapidly analyzed?</li> <li>Variety: How many different data types (raw files? databases?) A fourth V (Veracity) captures the need to make decisions about data processing (i.e., separating low- and high-quality data)</li> </ul> <p>3.  What is your strategy for storing and backing up your data?</p> <p>4.  What is your strategy for verifying the integrity of your data? (i.e. verifying that your data has not be altered)</p> <p>5.  What is your strategy for searching your data?</p> <p>6.  What is your strategy for sharing (and getting credit for) your data? (i.e. How will do you share with your community/clients? How is that sharing documented? How do you evaluate the impact of data shared? )</p> <p> </p>"},{"location":"02_managing_data/#the-data-life-cycle","title":"The Data Life Cycle","text":"<p>Tip</p> <p>The Data Life Cycle</p> <p>Data management is the set of practices that allow researchers to effectively and efficiently handle data throughout the data life cycle. Although typically shown as a circle (below) the actually life cycle of any data item may follow a different path, with branches and internal loops. Being aware of your data's future helps you plan how to best manage them.</p> <p></p> <p>Image from Strasser et al.</p> <p>The summary below is adapted from the excellent DataONE best practices primer.</p>"},{"location":"02_managing_data/#plan","title":"Plan","text":"<ul> <li>Describe the data that will be compiled, and how the data will be managed and made accessible throughout its lifetime</li> <li>A good plan considers each of the stages below</li> </ul>"},{"location":"02_managing_data/#collect","title":"Collect","text":"<ul> <li>Have a plan for data organization in place before collecting data</li> <li>Collect and store observation metadata at the same time you collect the metadata</li> <li>Take advantage of machine generated metadata</li> </ul>"},{"location":"02_managing_data/#assure","title":"Assure","text":"<ul> <li>Record any conditions during collection that might affect the quality of the data</li> <li>Distinguish estimated values from measured values</li> <li>Double check any data entered by hand</li> <li>Perform statistical and graphical summaries (e.g., max/min, average, range) to check for questionable or impossible values.</li> <li>Mark data quality, outliers, missing values, etc.</li> </ul>"},{"location":"02_managing_data/#describe","title":"Describe","text":"<ul> <li> <p>Comprehensive data documentation (i.e. metadata) is the key to     future understanding of data. Without a thorough description of     the context of the data, the context in which they were collected,     the measurements that were made, and the quality of the data, it     is unlikely that the data can be easily discovered, understood, or     effectively used.</p> </li> <li> <p>Thoroughly describe the dataset (e.g., name of dataset, list of     files, date(s) created or modified, related datasets) including     the people and organizations involved in data collection (e.g.,     authors, affiliations, sponsor). Also include:</p> <pre><code>-   An [ORCID](https://orcid.org/) (obtain one if you don't have one).\n-   The scientific context (reason for collecting the data, how they were collected, equipment and software used to generate the data, conditions during data collection, spatial and temporal resolution)\n-   The data themselves\n-   How each measurement was produced\n-   Units\n-   Format\n-   Quality assurance activities\n-   Precision, accuracy, and uncertainty\n</code></pre> </li> </ul> <p>Some metadata standards you may want to consider:</p> <ul> <li>DataCite for publishing data</li> <li>Dublin Core for sharing data on the web</li> <li>MIxS Minimum Information for any (x) sequence</li> <li>OGC standards for geospatial data</li> </ul> <p>Ontologies provide standardization for metadata values:</p> <ul> <li>Example: Environment Ontology terms for the MIxS standards</li> <li>Example: Plant Ontology for plant tissue types or development stages</li> <li>FAIRSharing.org lists standards and ontologies for life sciences.</li> </ul>"},{"location":"02_managing_data/#preserve","title":"Preserve","text":"<p>In general, data must be preserved in an appropriate long-term archive (i.e. data center). Here are some examples:</p> <ul> <li>Sequence data should go to a national repository, frequently NCBI</li> <li>Identify data with value - it may not be necessary to preserve all data from a project</li> <li>The CyVerse Data Commons provides a place to publish and preserve data that was generated on or can be used in CyVerse, where no other repository exists.</li> <li>See lists of repositories at FAIRSharing.org</li> <li>See lists of repositories at Data Dryad</li> <li>Github repos can get DOIs through Zenodo</li> <li>Be aware of licensing and other intellectual property issues<ul> <li>Repositories will require some kind of license, often the     least restrictive (see for example Creative Commons)</li> <li>Repositories are unlikely to enforce reuse restrictions, even     if you apply them.</li> </ul> </li> </ul>"},{"location":"02_managing_data/#discover","title":"Discover","text":"<ul> <li>Good metadata allows you to discover your own data!</li> <li>Databases, repositories, and search indices provide ways to     discover relevant data for reuse <ul> <li>Google dataset search</li> <li>DataOne</li> <li>FAIRSharing.org</li> </ul> </li> </ul>"},{"location":"02_managing_data/#integrate","title":"Integrate","text":"<ul> <li>Data integration is a lot of work</li> <li>Standards and ontologies are key to future data integration</li> <li>Know the data before you integrate them</li> <li>Don't trust that two columns with the same header are the same data</li> <li>Properly cite the data you reuse!</li> <li>Use DOIs (Digital Object Identifiers) wherever possible</li> </ul>"},{"location":"02_managing_data/#analyze","title":"Analyze","text":"<ul> <li>Follow open science principles for reproducible analyses (CyVerse,     RStudio, notebooks, IDEs)</li> <li>State your hypotheses and analysis workflow before collecting     data. Tools like Open Science Framework (OSF) allow you to make this public.</li> <li>Record all software, parameters, inputs, etc.</li> </ul>"},{"location":"02_managing_data/#references-and-resources","title":"References and Resources","text":"<p>DataOne best practices</p> <p>Center for Open Science</p> <p> </p>"},{"location":"02_managing_data/#the-principles-of-open-data-management","title":"The Principles of Open Data Management","text":"<p>Learning Objectives</p> <ul> <li>Recall the meanings of FAIR, CARE, and TRUST</li> <li>Understand why FAIR are ideals (rather than hard rules)</li> <li>Use self-assessments to evaluate the FAIR-ness of your data</li> </ul> Why do we have data principles? <p>FAIR, CARE, and TRUST are collections of principles from different types of communities with different objectives. </p> <p>Ultimately, different communities within different scientific disciplines must work to interpret and implement these principles. Because technologies change quickly, focusing on the desired end result allows FAIR to be applied to a variety of situations now and in the foreseeable future.</p>"},{"location":"02_managing_data/#fair-principles","title":"FAIR Principles","text":"<p>In 2016, the FAIR Guiding Principles for scientific data management and stewardship were published in Scientific Data. Read it.</p> <p>Findable</p> <ul> <li>F1. (meta)data are assigned a globally unique and persistent identifier</li> <li>F2. data are described with rich metadata (defined by R1 below)</li> <li>F3. metadata clearly and explicitly include the identifier of the data it describes</li> <li>F4. (meta)data are registered or indexed in a searchable resource</li> </ul> <p>Accessible</p> <ul> <li>A1. (meta)data are retrievable by their identifier using a     standardized communications protocol</li> <li>A2. the protocol is open, free, and universally implementable</li> <li>A3. the protocol allows for an authentication and authorization     procedure, where necessary</li> <li>A4. metadata are accessible, even when the data are no longer     available</li> </ul> <p>Interoperable</p> <ul> <li>I1. (meta)data use a formal, accessible, shared, and broadly     applicable language for knowledge representation.</li> <li>I2. (meta)data use vocabularies that follow FAIR principles</li> <li>I3. (meta)data include qualified references to other (meta)data</li> </ul> <p>Reusable</p> <ul> <li>R1. meta(data) are richly described with a plurality of accurate     and relevant attributes</li> <li>R2. (meta)data are released with a clear and accessible data     usage license</li> <li>R3. (meta)data are associated with detailed provenance</li> <li>R4. (meta)data meet domain-relevant community standard</li> </ul> <p>Open vs. Public vs. FAIR</p> <p>FAIR does not demand that data be open: See one definition of \"Open\":</p> <p>http://opendefinition.org/</p> How to be more FAIR with your data? <p>This is a question that only you can answer, that is because it depends on (among other things)</p> <ol> <li> <p>Your datatypes and existing standards for what constitutes acceptable data management will vary.</p> </li> <li> <p>The extent to which your scientific community has implemented FAIR: Some disciplines have significant guidelines on FAIR, while others have not addressed the subject in any concerted way.</p> </li> <li> <p>Your level of technical skills: Some approaches to implementing FAIR may require technical skills you may not yet feel comfortable with.</p> </li> </ol> <p>While a lot is up to you, the first step is to evaluate how FAIR you think your data are:</p> <p>Self Assessment</p> <p>Thinking about a dataset you work with, complete the ARDC FAIR assessment</p> <p>What did you learn about yourself and your data?</p>"},{"location":"02_managing_data/#care-principles","title":"CARE Principles","text":"<p>The CARE Principles for Indigenous Data Governance were drafted at the International Data Week and Research Data Alliance Plenary co-hosted event \"Indigenous Data Sovereignty Principles for the Governance of Indigenous Data Workshop,\" 8 November 2018, Gaborone, Botswana.</p> <p>Collective Benefit</p> <ul> <li>C1. For inclusive development and innovation</li> <li>C2. For improved governance and citizen engagement</li> <li>C3. For equitable outcomes</li> </ul> <p>Authority to Control</p> <ul> <li>A1. Recognizing rights and interests</li> <li>A2. Data for governance</li> <li>A3. Governance of data</li> </ul> <p>Responsibility</p> <ul> <li>R1. For positive relationships</li> <li>R2. For expanding capability and capacity</li> <li>R3. For Indigenous languages and worldviews</li> </ul> <p>Ethics</p> <ul> <li>E1. For minimizing harm and maximizing benefit</li> <li>E2. For justice</li> <li>E3. For future use</li> </ul> <p>Connecting FOSS and CARE: FOSS Alumnus Dr. Lydia Jennings{target=_blank</p> <p>Dr. Lydia Jennings was a Data Science Fellow at the University of Arizona who attended FOSS in Fall of 2022.</p> <p>Lydia graduated from the University of Arizona's Department of Evironemtal Sciences in 2023 and has published a paper on the application of the CARE principles to ecology and biodiversity research.</p> <p>Appying the 'CARE Principles for Indigenous Data Governance' to ecology and biodiversity Nature Ecology &amp; Evolution, 2023. </p> <p>More Resources for CARE &amp; Indigenous Rights</p> <ul> <li> <p>The FAIR Guiding Principles for scientific data management and stewardship</p> </li> <li> <p>Wilkinson et al. (2016) established the guidelines to improve the Findability, Accessibility, Interoperability, and Reuse (FAIR) of digital assets for research. </p> </li> <li> <p>Go-FAIR website</p> </li> <li> <p>Carroll et al. (2020) established the CARE Principles for Indigenous Data Governance. full document </p> </li> <li> <p>Indigenous Data Sovereignty Networks</p> </li> <li> <p>Local Contexts</p> </li> </ul>"},{"location":"02_managing_data/#trust-principles","title":"TRUST Principles","text":"<p>Lin et al. 2020 The TRUST Principles for digital repositories</p> <p>Transparency</p> <ul> <li> <p>Terms of use, both for the repository and for the data holdings.</p> </li> <li> <p>Minimum digital preservation timeframe for the data holdings.</p> </li> <li> <p>Any pertinent additional features or services, for example the capacity to responsibly steward sensitive data.</p> </li> </ul> <p>Responsibility</p> <ul> <li> <p>Adhering to the designated community\u2019s metadata and curation standards, along with providing stewardship of the data holdings e.g. technical validation, documentation, quality control, authenticity protection, and long-term persistence.</p> </li> <li> <p>Providing data services e.g. portal and machine interfaces, data download or server-side processing.</p> </li> <li> <p>Managing the intellectual property rights of data producers, the protection of sensitive information resources, and the security of the system and its content.</p> </li> </ul> <p>User focus</p> <ul> <li> <p>Implementing relevant data metrics and making these available to users.</p> </li> <li> <p>Providing (or contributing to) community catalogues to facilitate data discovery.</p> </li> <li> <p>Monitoring and identifying evolving community expectations and responding as required to meet these changing needs.</p> </li> </ul> <p>Sustainability</p> <ul> <li> <p>Planning sufficiently for risk mitigation, business continuity, disaster recovery, and succession.</p> </li> <li> <p>Securing funding to enable ongoing usage and to maintain the desirable properties of the data resources that the repository has been entrusted with preserving and disseminating.</p> </li> <li> <p>Providing governance for necessary long-term preservation of data so that data resources remain discoverable, accessible, and usable in the future.</p> </li> </ul> <p>Technology</p> <ul> <li> <p>Implementing relevant and appropriate standards, tools, and technologies for data management and curation.</p> </li> <li> <p>Having plans and mechanisms in place to prevent, detect, and respond to cyber or physical security threats.</p> </li> </ul>"},{"location":"02_managing_data/#references-and-resources_1","title":"References and Resources","text":"<p>https://www.nature.com/articles/sdata201618</p> <p> </p>"},{"location":"02_managing_data/#data-management-plans","title":"Data Management Plans","text":"<p>Learning Objectives</p> <ul> <li>Describe the purpose of a data management plan</li> <li>Describe the important elements of a data management plan</li> <li>Use a self-assessment to design a data management plan</li> </ul>"},{"location":"02_managing_data/#what-is-a-dmp","title":"What is a DMP?","text":"<p>\"A data management plan or DMP is a formal document that outlines how data are to be handled both during a research project, and after the project is completed. [1] The goal of a data management plan is to consider the many aspects of data management, metadata generation, data preservation, and analysis before the project begins; this may lead to data being well-managed in the present, and prepared for preservation in the future.\"(Source: https://en.wikipedia.org/wiki/Data_management_plan)</p> <p>Example DMPs</p> <p>Bishop article on DMPs</p> <p>Why bother with a DMP?</p> <p>How would you answer?</p> <p>Do you have a data management plan? If so, how do you use it?</p> <p>\"Those who fail to plan, plan to fail\"</p> <p>Returning to the assertion that data (and its value) is at the foundation of your science, working without a data management plan should be considered scientific misconduct.</p> <p>Those are strong words. And while we might have an intuition of the boundaries of research ethics - data mismanagement seems more like an annoyance than misconduct. However, if your mismanagement leads to error in your research data, or the inability to make publicly-funded research open to the public, these are serious consequences. Increasingly, funders realize this.</p> <p>Stick:</p> <ul> <li>You have to make one</li> <li>Reviewers definitely look at them, but they may not be enforced.</li> </ul> <p>Carrot:</p> <ul> <li>Make your life easier</li> <li>Planning for you project makes it run more smoothly</li> <li>Avoid surprise costs</li> </ul> <p> </p> <p>DMP Tools</p> <p>Make your life a little easier by creating DMPs with online tools </p> <p>Data Stewardship Wizard</p> <p>DMPTool</p> <p> </p> <p> </p>"},{"location":"02_managing_data/#licenses","title":"Licenses","text":"<p>By default, when you make creative work, that work is under exclusive copyright. This means that you have the right to decide how your work is used, and that others must ask your permission to use your work.</p> <p>If you want your work to be Open and used by others, you need to specify how others can use your work. This is done by licensing your work.</p> <p> </p> <p>License Examples</p> <p>MIT License</p> <p>GNU General Public License v3.0</p> <p>FOSS material has been licensed using the Creative Commons Attribution 4.0 International License.</p> <p> </p>"},{"location":"02_managing_data/#license-options-from-uarizona-library","title":"License Options from UArizona Library","text":"<p>  License options for University of Arizona Research Data Repository (ReDATA) </p> <p></p>"},{"location":"02_managing_data/#additional-info","title":"Additional Info","text":"<p>General guidance on how to choose a license https://choosealicense.com/</p> <p>More good guidance on how to choose a license https://opensource.guide/legal/</p> <p>Licensing options for your Github Repository</p>"},{"location":"02_managing_data/#references-and-resources_2","title":"References and Resources","text":"<ul> <li>NSF Guidelines on DMPs</li> <li>https://dmptool.org/general_guidance</li> <li>https://dmptool.org/public_templates</li> <li>Professional and scholarly societies, e.g., theEcological Society of America http://www.esa.org/esa/science/data-sharing/resources-and-tools/</li> <li>DataOne - https://dataoneorg.github.io/Education/bestpractices/</li> <li>Data Carpentry - http://datacarpentry.org/</li> <li>The US Geological Survey https://www.usgs.gov/data-management</li> <li>Repository registry (and search) service: http://www.re3data.org/</li> <li>Your university library</li> </ul>"},{"location":"02_managing_data/#self-assessment","title":"Self Assessment","text":"What is a Data Management Plan? <p>Important: A data management plan (DMP) is now required aspect of publicly funded research.</p> <p>DMPs are short, formal, documents outlining what types of data will be used, and what will be done with the data both during and after a research project concludes.</p> True or False: When science project funding ends, the data should end with it <p>False</p> <p>Data live on after a project ends.</p> <p>Ensuring that data have a full lifecycle where they can be (re)hosted and made available after a project ends is critical to open science and reproducible research</p> <p>Maybe</p> <p>Sometimes destroying data is part of the life cycle of data - this may be required if data are sensitive and could be used unethically in the future, beyond the control of the original investigator team. </p> True or False: FAIR and CARE data principles are the same <p>False</p> <p>The CARE principles were created in order to help guide and answer when and how applying FAIR data principles to soverign indigenous-controlled data should be done and when it should not. </p>"},{"location":"03_project_management/","title":"Introduction to Project Management","text":"<p>Learning Objectives</p> <p>After this lesson, you should be able to:</p> <ul> <li>Discuss different levels of project management</li> <li>Describe tools and approaches to managing collaborative projects</li> <li>Describe best practices for computational project organization</li> <li>Understand benefits of establishing project management practices from the start of a project until after it ends</li> </ul> <p>\"Project Management\" by itself may sound a bit vague and broad. </p> Definition <p>\"Project management is the use of specific knowledge, skills, tools and techniques to deliver something of value to people. The development of software for an improved business process, the construction of a building, the relief effort after a natural disaster, the expansion of sales into a new geographic market\u2014these are all examples of projects.\" - Project Management Institute </p> <p> Wikipedia definition</p> <p>Here we use the term in two different contexts.</p> <ol> <li> <p>First, we'll go over the project management of scientific labs, groups, and projects, talking about things like governance, how to develop operations manuals, laying out roles and responsibilities, planning steps and the workflows which connect them. </p> </li> <li> <p>Next, we'll go over project management as \"research objects\": making sure your data, code, and documents are well-organized. These are crucial for future topics like version control and reproducibility.</p> </li> </ol>"},{"location":"03_project_management/#1-classic-project-management","title":"1. Classic Project Management","text":"<p>This type of overall project management may be required for some grants, and while it may be tempting to put in the minimal effort on one of the many pieces of paperwork you're required to complete, this type of overall project planning can be very useful. </p> Traditional Organizations <p>Major research (R1) universities are organized around hierarchical frameworks, often described using an Organizational Chart.</p> <p> </p> <p>Scientific Research Projects are generally organized around a \"Principal Investigator\" with \"Co-Principal Investigators\" and \"Senior Personnel\" in supporting roles. Postdoctoral Researchers and gradaute students are often employed by research projects as part of their continued education and \"professional preparation\". </p> <p></p> <p>Given the nebulous breakdown of authority within lab groups and small research projects, the organization and governance of teams can be difficult to determine from the outside perspective. Indeed, internally team members on projects often do not know who is in charge or who reports to whom.</p> <p>The Turing Way offer a lesson on Project Design related to effective project planning and management.</p>"},{"location":"03_project_management/#project-governance","title":"Project Governance","text":"Definitions <p>Project Governance is the set of rules, procedures and policies that determine how projects are managed and overseen.</p> <p>\"The set of policies, regulations, functions, processes, and procedures and responsibilities that define the establishment, management and control of projects, programmes or portfolios.\" - APM (2012), open.edu</p> <p> Wikipedia Definition</p> <p>No matter how small, i.e., even single person-run projects, a good Project Governance structure can help keep work on track and headed toward a timely finish.</p> <p>Establishing a project governance document at the onset of a project is a good way of setting boundaries, roles and responsibilities, pre-registration about what deliverables are expected, and what the consequences will be for breaking trust.</p> Example Governance Documents <p>Munoz-Torres et al. 2020</p>"},{"location":"03_project_management/#research-collaborations","title":"Research Collaborations","text":"<p>Sahneh &amp; Balk et al. (2020) Ten simple rules to cultivate transdisciplinary collaboration in data science, discuss the interactions amongst teams of diverse researchers.</p> <p> Sahneh &amp; Balk et al. (2020) Fig 1. How the rules work together and intersect. There are multiple components in collaborations: person\u2013person interactions, person\u2013technology interactions, person\u2013data interactions, and data\u2013technology interactions. Synergy between these components results in a successful collaboration. </p>"},{"location":"03_project_management/#team-roles-and-responsibilities","title":"Team Roles and Responsibilities","text":"<p>It can be easy for certain tasks to slip through the cracks. Established roles and responsibilities of teams can help ensure nobody gets saddled with too much work, and reduces chances of disputes among collaborators.</p> Project Management Professional (PMP)\u00ae <p>A Project Management Professional (PMP)\u00ae certification has been embraced globally as adding value to your professional resume. </p> <p>Academia has also embraced PMP certification as part of continuing education for academic staff and faculty.</p> <p>University of Arizona PMP prep</p> Team roles and titles <p>Again, The Turing Way provide an excellent set of examples of infrastructure job titles and roles on software driven projects:</p> <p>Community Manager - \"responsibilities include establishing engagement, organising community spaces and events, supporting people through inclusive practices, developing and maintaining resources, growing and evaluating use cases and collaborating with people involved in research and scientific communities.\" (1, 2)</p> <p> This image was created by Scriberia for The Turing Way community and is used under a CC-BY 4.0 licence. </p> <p>Data Science Educator - \"... data science in education refers to the application of data science methods, while other times it refers to data science as a context for teaching and learning\" Rosenberg et al. (2020), Estrellado et al.</p> <p>Data Scientist - a professional who uses analytical, statistical, and programming skills to collect, analyze, and describe data.</p> <p>Data Steward - \"... responsible for ensuring the quality and fitness for purpose of the organization's data assets, including the metadata for those data assets.\" - Wikipedia</p> <p>Developer Advocate - sometimes called platform evangelism, advocates represent the voice of the user (in the case of open science, the scientists) internally to the project team or company, and the voice of the project or company externally to the public.</p> <p>DevOps Engineer - a combinination of software development \"Dev\" and IT operations \"Ops\", responsibilities focus on \"continuous delivery\" and agile software development</p> <p>Research Application Manager (RAM) - in some ways a combination of Community Manager and Developer Advocate,</p> <p> Fig. 94 Research Application Managers work with the research team to embed outputs into user organisations. The Turing Way Community, &amp; Scriberia. (2020, November). Illustrations from the Turing Way book dashes. Zenodo. http://doi.org/10.5281/zenodo.4323154 </p> <p>Research Software Engineer - those who regularly use expertise in programming to advance research - US Research Software Engineer (US-RSE) Association</p>"},{"location":"03_project_management/#open-source-research-software-maintainer","title":"Open Source Research Software Maintainer","text":"<p>Becoming an open source software maintainer is not to be taken lightly.</p> <p>  Image Credit: XKCD Dependency </p> <p>When you create a new software, library, or package, you are becoming its parent and guardian. </p>"},{"location":"03_project_management/#development-methodology","title":"Development Methodology","text":"the \"leaps of faith\" required in Agile vs Waterfall. Image Credit: Wikimedia Commons CC BY 4.0  <p>In software development, there are two common methologies which have similar applications to a research project:</p> <ul> <li> Agile<ul> <li>Scrum</li> <li>Kanban</li> </ul> </li> <li> Waterfall</li> </ul> <p> </p>  the effort distribtion of Agile vs Waterfall. Image Credit: Wikimedia Commons CC BY 4.0  <p>Comparisons between methodologies</p> <ul> <li> <p>LucidChart Blog: Agile vs Waterfall vs Kanban vs Scrum  </p> </li> <li> <p>Ontology of Value: Agile vs Waterfall vs Kanban vs Scrum</p> </li> </ul>"},{"location":"03_project_management/#breakout-discussion","title":"Breakout Discussion","text":"<p>Now we will do a breakout discussion section to talk about overall project management.</p> <p>What is an example of a poorly managed project you were involved in? What contributed to this feeling?</p> <p>Why do you think effective project management is important to Open Science?</p> <p>What are some limitations to you, your lab/group, or your domain?</p>"},{"location":"03_project_management/#2-research-objects","title":"2. Research Objects","text":"Definition <p>\"A workflow-centric research object bundles a workflow, the provenance of the results obtained by its enactment, other digital objects that are relevant for the experiment (papers, datasets, etc.), and annotations that semantically describe all these objects.\" - Corcho et al. 2012</p> <p>\"... semantically rich aggregations of resources, that can possess some scientific intent or support some research objective.\" - Bechhofer et al. 2010</p> <p> Wikipedia definition</p> <p>When we talk about project management in this section, we mean the way you organize data, code, images, documents, and documentation within a project. One way to think about this is in the context of \"research objects\" which condense into a single end point (think: a URL like a digital object identifier (DOI)) where others can come to reproduce your research. </p> Examples of Research Objects <p>Boettiger 2018</p> <p>Gillan et al. 2021</p> <p>  Research Objects from ResearchObject.org</p> Research Object Services <p>ResearchObject</p> <p>ROHub - Garcia-Silva et al. 2019</p>"},{"location":"03_project_management/#research-object-organization","title":"Research Object Organization","text":"<p>If you've ever had to navigate someone else's computer or a GitHub repository, you probably know that a poorly organized project can greatly reduce its accessibility. On the other hand, a well-organized project can:</p> <ul> <li>make your work more accessible to others</li> <li>help collaborators effectively contribute to your project</li> <li>ease the growing pains of a rapidly scaling project</li> <li>make life much easier for your future self</li> </ul> <p>It can be easy to overlook sound project management, opting for a \"just get it done ASAP\" approach to your work, but this almost always costs you more time in the end. The best time to introduce good project management is at the start of a project, and the second best time is right now. </p> <p>  An hour spent reorganizing a project today may save you days of headaches later on.</p>"},{"location":"03_project_management/#organization-examples","title":"Organization Examples","text":"<ul> <li>Example data project organization from UArizona Libraries</li> <li>CookieCutter Templates</li> </ul> <p>Example project structure:</p> <pre><code>.\n\u251c\u2500\u2500 AUTHORS.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 bin                &lt;- Your compiled model code can be stored here (not tracked by git)\n\u251c\u2500\u2500 config             &lt;- Configuration files, e.g., for doxygen or for your model if needed\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 external       &lt;- Data from third party sources.\n\u2502   \u251c\u2500\u2500 interim        &lt;- Intermediate data that has been transformed.\n\u2502   \u251c\u2500\u2500 processed      &lt;- The final, canonical data sets for modeling.\n\u2502   \u2514\u2500\u2500 raw            &lt;- The original, immutable data dump.\n\u251c\u2500\u2500 docs               &lt;- Documentation, e.g., doxygen or scientific papers (not tracked by git)\n\u251c\u2500\u2500 notebooks          &lt;- Ipython or R notebooks\n\u251c\u2500\u2500 reports            &lt;- For a manuscript source, e.g., LaTeX, Markdown, etc., or any project reports\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        &lt;- Figures for the manuscript or reports\n\u2514\u2500\u2500 src                &lt;- Source code for this project\n    \u251c\u2500\u2500 data           &lt;- scripts and programs to process data\n    \u251c\u2500\u2500 external       &lt;- Any external source code, e.g., pull other git projects, or external libraries\n    \u251c\u2500\u2500 models         &lt;- Source code for your own model\n    \u251c\u2500\u2500 tools          &lt;- Any helper scripts go here\n    \u2514\u2500\u2500 visualization  &lt;- Scripts for visualisation of your results, e.g., matplotlib, ggplot2 related.\n</code></pre> Best Practices <ol> <li> <p>Projects should be self-contained</p> <ul> <li>this is probably the most important concept</li> <li>strictly necessary for version control</li> <li>use relative paths</li> </ul> </li> <li> <p>Use structure to organize files</p> </li> <li> <p>Don't underestimate complexity</p> </li> <li> <p>Keep raw data raw</p> </li> <li> <p>Treat generated output as disposable</p> </li> <li> <p>Avoid manual (point-and-click) steps as much as possible</p> <ul> <li>if necessary, record in detail</li> <li>should also be recorded in prior and subsequent steps</li> </ul> </li> <li> <p>Avoid spaces in file and folder names</p> <ul> <li>consider <code>snake_case</code> <code>camelCase</code> <code>PascalCase</code> <code>kebab-case</code> instead</li> </ul> </li> <li> <p>Describe structure in README</p> </li> <li> <p>The best time to organize is at the start, the 2<sup>nd</sup> best is right now</p> </li> <li> <p>Reorganize if necessary, but don't overdo it</p> </li> <li> <p>Using same basic structure can help you navigate new/old projects</p> </li> </ol> Automate the creation a working directory <p>You might find a nice basic structure that works as a good starting place for many of your projects, or smaller components of big projects.</p> <p>Instead of having to repeat the process of making that directory structure, which could be tedious and introduce mistakes, you could write some code to do it for you. </p> <p>The following is a <code>bash</code> script that takes one argument, the name of the new project (with no spaces), and creates that project with a premade directory structure for you to put files into.</p> <pre><code>#!/usr/bin/env bash\n\n# Run this script with the name of the new project as \n# an argument, like so: `bash make_project.sh my_project`\n# It will generate a project with the following structure:\n\n#.\n#|-- README.md\n#|-- data\n#|   |-- cleaned\n#|   `-- raw\n#|-- images\n#|-- reports\n#`-- scripts\n\nmkdir \"$1\"\n\ncd \"$1\" || exit\n\necho \"# $1\" &gt;&gt; README.md\n\nmkdir data\n\nmkdir data/raw\n\nmkdir data/cleaned\n\nmkdir scripts\n\nmkdir images\n\nmkdir reports\n</code></pre> <p>This approach to automating repetitive tasks is something we'll dig into even deeper in later lessons.</p> Productivity Software <p> CryptPad - online rich text pad. </p> <p> Draw.io - drawings and diagrams in browser.</p> <p> Excel - love it or hate it, many people still work in it or with <code>.xlsx</code> format files. </p> <p> Google Docs - is an online word processor included as part of the free, web-based Google Docs Editors suite offered by Google.</p> <p> HackMD - online markdown editor.</p> <p> JupyterBook - create documentation using Jupyter Notebooks and Markdown</p> <p> MkDocs - is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation.</p> <p> LaTeX -  is a high-quality typesetting system</p> <p> Overleaf - LaTeX online document sharing platform.</p> <p> ReadTheDocs - documentation using a variety of Markup langages</p> <p>Software Heritage - preserves software source code for present and future generations.</p>  Project Management Software <p>OSF.io</p> <ul> <li>Examples</li> </ul> <p> Atlassian</p> <ul> <li> <p> Confluence</p> </li> <li> <p> Jira</p> </li> <li> <p> Trello</p> </li> </ul> <p> GitHub Issues</p> <p>Open Project</p> <p> ZenHub</p> <p>Basecamp</p>"},{"location":"03_project_management/#breakout-discussion_1","title":"Breakout Discussion","text":"<p>Now we will do a breakout discussion section to talk about research objects</p> <p>Who here has created a research object or attempted to?</p> <p>Do you think someone could reproduce your research by accessing your research object?</p> <p>Where might a research object not work for your research?</p> <p>What would a research object look like for your research?</p>"},{"location":"03_project_management/#other-resources","title":"Other Resources","text":"<p>There are many other resources on more specific elements of project management. We'll link to some of them here.</p> <ul> <li>Using R Projects with RStudio: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects</li> <li>Using the R package <code>here</code>: https://github.com/jennybc/here_here and https://here.r-lib.org/</li> <li>An even more compartmentalized approach to project management: https://hrdag.org/2016/06/14/the-task-is-a-quantum-of-workflow/</li> </ul>"},{"location":"03_project_management/#self-assessment","title":"Self Assessment","text":"Why is Project Management used in research? <ol> <li> <p>Reduces [wasted] effort </p> </li> <li> <p>Tracks progress or identifies more quickly when there is a lack of progress</p> </li> <li> <p>Establishes a formal structure for teams</p> </li> </ol> What are established roles and responsibilities of collaborative teams? <p>Example 1: Traditional University Research Teams</p> <p>i. Principal Investigator, Co-Principal Investigators</p> <p>ii. Senior Personnel, Postdoctoral Researchers, Bench Scientists </p> <p>iii. (Graduate) Students</p> <p>Example 2: Research Infrastructure Teams</p> <p>Research infrastructure job titles and roles (Turing Way)</p> <p>i. Community Managers</p> <p>ii. Data Science Educators</p> <p>iii. Data Scientists</p> <p>iv. Developer Advocates</p> <p>iv. Research Software Engineers</p> What are some uses of a Project Governance Document? Answers <ul> <li> <p>Sets expectations for behavior and operations</p> </li> <li> <p>Establishes roles and responsibilities of PI, staff, and senior personnel</p> </li> <li> <p>Uses Pre-registration techniques about what deliverables are expects, and by when </p> </li> <li> <p>Establishes what consequences will be for breaking trust</p> </li> </ul> Research Objects must include all components of research: governance document, manuals, documentation, research papers, analysis code, data, software containers Answers <p>While a Research Object (RO) may include the entire kitchen sink from a research project, it does NOT always contain all of these things.</p> <p>Fundamentally, a RO should contain enough information and detail to reproduce a scientific study from its linked or self-contained parts. </p> <p>Components like large datasets may not be a part of the RO, but the code or analysis scripts should have the ability to connect to or stream those data.</p>"},{"location":"04_talk_to_computer/","title":"How to Talk to Computers","text":""},{"location":"04_talk_to_computer/#the-command-line-interface","title":"The Command Line Interface","text":"<p>When using a computer, it is typical to use a keyboard and mouse to navigate a cursor across the screen or simply tap on the screens of our smart phones or tablets. Both of these methods make use of the Graphical User Interface (GUI) and have become central to the way we interact with computers. GUIs make computers so easy to use! </p> <p>However, for a more direct and powerful way to instruct your computer, you should learn to use the Command Line Interface (CLI). CLIs are found throughout all operating systems (Windows, MacOS, Linux) though they might have different commands and syntax. </p> <p>For this FOSS lesson on CLI, we will focus on the Unix CLI which is present in MacOS and all Linux operating systems. </p> <p> </p> <p>Attention  Windows users</p> <p>Much of what we are going to be teaching is based on open-source software which operates on cloud and is incompatible with Windows OS.</p> <p>Unix-based systems such as Linux  Ubuntu and  MacOS X, as many scientific tools require a Unix Operating System (OS). </p> <p>There are a number of software that allow  Windows users to execute Unix commands, however we recommend the use of  Windows Subsystem for Linux (WSL) 2.0.</p> Quickstart installation of Window's WSL <p>A system reboot is necessary</p> <ol> <li>Open  PowerShell in Administrator mode (open  Search and look for PowerShell, right click and select \"Run as Administrator\")</li> <li>type <code>wsl --install</code></li> <li>Restart your machine</li> <li>Open  Search and open  WSL; create a username and password, wait for it to finish setting up (should take a few minutes)</li> <li>You're now ready to use  Linux on your Windows Machine!</li> </ol> Where is the WSL Home folder? <p>The Home folders for Linux and Windows are different. The Windows path to the  WSL home folder is <code>\\\\wsl$\\Ubuntu\\home\\&lt;username&gt;</code>.</p> <p>We suggest creating a bookmark in your Windows machine to allow quicker access to the  Linux partition (for quicker access to files).</p> <p>To quickly open the folder, open  WSL and execute <code>explorer.exe .</code>. This will open a folder in Windows at the Linux Home folder. </p> <p> </p> <p> </p>"},{"location":"04_talk_to_computer/#the-unix-shell","title":"The Unix Shell","text":"<p>The CLI sees the computer stripped down to only a Terminal from where one can run powerful commands executed through the Shell.</p> <p>Though there are technical differences between them, the terms Command Line Interface, Terminal, Shell, and BASH will be used more or less interchangeably throughout the lesson. </p> <p>  The Terminal shell</p> <p> </p> Quick video on the shell. <p> </p>"},{"location":"04_talk_to_computer/#introductory-shell-commands","title":"Introductory Shell Commands","text":"<p>The following tutorial material was taken from the Carpentries' Shell Module. </p> <p>Download Some Data from the Carpentries</p> <p>To follow along with the tutorial, please download and unzip this data. shell-lesson-data.zip </p> The Command Line Way to Download and Unzip! <p>Execute the following commands: <pre><code>$ sudo apt install unzip\n$ wget https://swcarpentry.github.io/shell-novice/data/shell-lesson-data.zip\n$ unzip shell-lesson-data.zip\n</code></pre></p> <p> </p> Help with Commands <p>For every command, typing <code>man</code> (manual) before the command, will open the manual for said command. <pre><code>$ man ls\n</code></pre></p> <ul> <li>The above command will result in opening the manual for the <code>ls</code> command. You can exit the man page by pressing <code>q</code>.</li> </ul> Command Flags <p>Each command has flags, or options that you can specify. which are summoned with a <code>-</code>, such as <code>&lt;command&gt; -&lt;flag&gt;</code>. <pre><code>$ ls -a -l -h\n</code></pre></p> <ul> <li> <p>The above command calls for the <code>-a</code> (all), <code>-l</code> (long), <code>-h</code> (human readable) flags. This causes <code>ls</code> to output a list of all files (inculding hidden files/folders) with human readable file size (e.g., it will list 3MB instead of 3000000), permissions, creator, and date of creation.</p> </li> <li> <p>If you do not know what flags are available, you can refer to the <code>man</code> command (or for many tools, use the <code>-h</code> (help) flag).</p> </li> </ul> Tips for Directory Navigation <p><code>.</code> refers to current directory</p> <p><code>..</code> refers to above directory</p> <p><code>/</code> is the directory separator</p> <p><code>~</code> indicates the home directory</p> <p>For example: <pre><code>$ ls .            # lists files and folders in the current directory\n$ ls ..           # lists files and folders in the above directory\n$ ls ~            # lists files and folders in the home directory\n$ ls ~/Documents  # lists files and folders in Documents (a folder present in the home directory)\n</code></pre></p> <p> </p> <p>  Linux Directory Structure</p>"},{"location":"04_talk_to_computer/#navigation","title":"Navigation","text":"Command Explanation <code>pwd</code> print working directory <code>ls</code> list content of folder <code>cd</code> change directory <p>By typing <code>pwd</code>, the current working directory is printed.</p> <p><pre><code>$ pwd\n\n/home/jgillan\n</code></pre> </p> <p>We can then use <code>ls</code> to see the contents of the current directory. By using the <code>-F</code> flag (<code>ls -F</code>) we can also see the type of file. Note: an asterisk (<code>*</code>) at the end of the object will denote a file, whilst a slash (<code>/</code>) will denote a folder.</p> <p><pre><code>$ ls -F \nshell-lesson-data/   shell-lesson-data.zip*\n</code></pre> </p> <p>We can then move inside the folder of our choice doing <code>cd</code>. Doing <code>ls</code> following the opening of the folder of choice, will show the contents of the folder you just moved in. Feel free to explore the contents of the folders by using <code>cd</code> and <code>ls</code>.</p> <p><pre><code>$ cd shell-lesson-data\n$ ls -F\n\nexercise-data/  north-pacific-gyre/\n\n$ ls -F exercise-data/\n\nanimal-counts/  creatures/  numbers.txt*  proteins/  writing/\n</code></pre> </p> <p>Use the Tab key to autocomplete</p> <p>You do not need to type the entire name of a folder or file. By using the tab key, the Shell will autocomplete the name of the files or folders. For example, typing the following</p> <pre><code>$ ls -F exer\n</code></pre> <p>and pressing the tab key, will result in autocompletion.</p> <pre><code>$ ls -F exercise-data/\n</code></pre> <p>You can then press tab twice, to print a list of the contents of the folder.</p> <pre><code>$ ls -F exercise-data/\nanimal-counts/ creatures/     numbers.txt    proteins/      writing/ \n</code></pre> <p> </p>"},{"location":"04_talk_to_computer/#working-with-files-and-directories","title":"Working with Files and Directories","text":"Command Explanation <code>mkdir</code> make a directory <code>touch</code> creat empty file <code>nano</code> or <code>vim</code> text editors <code>mv</code> move command <code>cp</code> copy command <code>rm</code> remove command <p>Return to <code>shell-lesson-data</code>, and create a directory with <code>mkdir &lt;name of folder&gt;</code>.</p> <pre><code>$ mkdir my_folder\n$ ls -F\n\nexercise-data/  my_folder/  north-pacific-gyre/\n</code></pre> <p>Notice the new <code>my_folder</code> directory.</p> <p> </p> <p>Naming your files</p> <p>It is strongly suggested that you avoid using spaces when naming your files. When using the Shell to communicate with your machine, a space can cause errors when loading or transferring files. Instead, use dashes (<code>-</code>), underscores (<code>_</code>), periods (<code>.</code>) and CamelCase when naming your files.</p> <p>Acceptable naming: <pre><code>$ mkdir my_personal_folder\n$ mkdir my_personal-folder\n$ mkdir MyPersonal.Folder\n</code></pre> </p> What will happen if you create a directory with spaces? <p>You will obtain as many folders as typed words! <pre><code>$ mkdir my folder\n$ ls -F\nexercise-data/  folder/  my/  north-pacific-gyre/\n</code></pre> Notice the two folders <code>my</code> and <code>folder</code>.</p> <p> </p> <p>Create an empty file with <code>touch &lt;name of file&gt;</code></p> <pre><code>$ touch new_file.txt\n</code></pre> <p><code>touch</code> will create an empty file</p> <p></p> <p>Add text to the new file <pre><code>nano new_file.txt \n</code></pre></p> <p> </p> <p>Use <code>mv &lt;name of file or folder you want to move&gt; &lt;name of destination folder&gt;</code> to move your newly created file to the directory you created previously (you can then use <code>ls</code> to check if you successully moved the file).</p> <p><pre><code>$ ls -F\nexercise-data/  new_file*  my_folder/  north-pacific-gyre/\n\n$ mv new_file.txt my_folder/\n$ ls -F\nexercise-data/  my_folder/  north-pacific-gyre/\n\n$ ls -F my_folder/\nnew_file.txt*\n</code></pre> <code>mv</code> can also be used to rename a file or folder with  <code>mv &lt;name of file or folder you want to change&gt; &lt;new name&gt;</code>.</p> <pre><code>$ cd my_folder/\n$ mv new_file my_file\n$ ls -F\nmy_file*\n</code></pre> <p> </p> <p><code>cp</code> is the command to copy a file with the syntax <code>cp &lt;name of file you want to copy&gt; &lt;name of copy file&gt;</code></p> <pre><code>$ cp my_file copy_my_file\n$ ls -F \ncopy_my_file*  my_file*\n</code></pre> <p>Copying folders</p> <p>To copy folders and the content of these folders, you will have to use the <code>-r</code> flag (recursive) for <code>cp</code> in the following manner <code>cp -r &lt;name of folder you want to copy&gt; &lt;name of copy folder&gt;</code> (following example is from the <code>shell-lesson-data/</code> directory). <pre><code>$ cp -r my_folder/ copy_my_folder\n$ ls -F\ncopy_my_folder/  exercise-data/  my_folder/  north-pacific-gyre/\n\n$ ls -F my_folder/\ncopy_my_file*  my_file*\n\n$ ls -F copy_my_folder/\ncopy_my_file*  my_file*\n</code></pre></p> <p> </p> <p>To remove an unwanted file, use <code>rm &lt;name of file to remove&gt;</code>.</p> <pre><code>$ rm copy_my_file\n$ ls -F \nmy_file\n</code></pre> <p>Removing folders</p> <p>Save as the \"Copying Folders\" note, you have to use the <code>-r</code> flag to remove a folder <code>rm -r &lt;name of folder you want to remove&gt;</code> (following example is from the <code>shell-lesson-data/</code> directory). <pre><code>$ rm -r copy_my_folder/\n$ ls -F\nexercise-data/  my_folder/  north-pacific-gyre/\n</code></pre></p> <p> </p>"},{"location":"04_talk_to_computer/#shell-script","title":"Shell Script","text":"<p>Here we are going to show an example command line automation using a shell script. This is what makes the command line powerful!</p> <p>Shell Script</p> <p>A shell script is a file with the extension '.sh'. It is essentially a text file that lists out multiple shell commands. When the shell script is run, the computer will run all of the commands in sequence in an automated way.  </p> <p></p> <p>Navigate to the <code>shell-lesson-data</code> directory</p> <pre><code>$ cd /home/jgillan/shell-lesson-data\n</code></pre> <p></p> <p>Create the shell script</p> <p><pre><code>$ nano backup.sh\n</code></pre> The text editor Nano will pop up and it will be empty.</p> <p></p> <p>Copy and paste the following commands into <code>backup.sh</code></p> <p><pre><code>#use Bash shell to run the following commands\n#!/bin/bash\n\n## Variables\n#the directory you want to back up (e.g., shell-lesson-data)\nSOURCE_DIR=\"$HOME/Documents/shell-lesson-data\"\n\n#location where the backup will be stored\nBACKUP_DIR=\"$HOME/Backup\"\n\n#used to create a unique name for each backup based on the current date and time\nTIMESTAMP=$(date +\"%Y-%m-%d_%H-%M-%S\")\n\n# name of the compressed backup file\nARCHIVE_NAME=\"backup_$TIMESTAMP.tar.gz\"\n\n\n# Create backup directory if it doesn't exist\nmkdir -p \"$BACKUP_DIR\"\n\n# Create a compressed archive of the source directory\ntar -czf \"$BACKUP_DIR/$ARCHIVE_NAME\" -C \"$SOURCE_DIR\" .\n\n# Output the result\necho \"Backup of $SOURCE_DIR completed!\"\necho \"Archive created at $BACKUP_DIR/$ARCHIVE_NAME\"\n</code></pre> </p> <p>Exit nano with <code>ctrl + x</code></p> <p></p> <p>Modify permission to make the shell script executable <pre><code>$ chmod +x backup.sh\n</code></pre></p> <p></p> <p>Run the shell script <pre><code>$ ./backup.sh\n</code></pre></p> <p> Go back to your home directory and look for the new backup directory <pre><code>$ cd ~\n$ cd ls\n</code></pre></p> <p>There should be a new directory called 'Backup' with a compressed file within it. </p> <p> </p>"},{"location":"04_talk_to_computer/#more-carpentries-lessons-on-linux-command-line","title":"More Carpentries Lessons on Linux Command line","text":"<ul> <li>Pipes and Filters</li> <li>Loops</li> <li>Scripts</li> <li>Finding Things</li> </ul>"},{"location":"04_talk_to_computer/#llm-chatbots-for-open-science","title":"LLM Chatbots for Open Science","text":"<p>Large Language Model (LLM) chatbots have fundamentally changed how we humans are going to interact with computers going forward. They provide a natural language interface to instruct computers to do many tasks including:</p> <ul> <li>Read, write, and summarize text</li> <li>Analyze data</li> <li>Explain techical topics</li> <li>Search the web and retrieve information</li> <li>Generate, optimize, and explain many types of computer code </li> <li>Understand and generate images</li> </ul> <p></p> <p>Current LLMs generally provide recommendation for how you could do things. ie, they provide you code and text recommendations but don't actually execute anything. But these technologies are advancing quickly and new capabilities are developed and released constantly. Soon, AI Agents could be everywhere executing on instructions in autonomous and semi-autonomous ways.</p> <p></p>"},{"location":"04_talk_to_computer/#commercial-chatbots","title":"Commercial Chatbots","text":"<ul> <li> ChatGPT</li> <li> Gemini</li> <li> Claude</li> <li> Copilot</li> </ul>"},{"location":"04_talk_to_computer/#llms-in-150-words-or-less","title":"LLMs in 150 words (or less)","text":"<p>How they're made: LLMs work by training on vast amounts of text from the internet. They learn patterns, grammar, and context from this data. When you give them a prompt, they generate text based on what they've learned. Imagine a super-smart autocomplete for text, but it can also create entire paragraphs or articles.</p> <p>How they work: LLMs don't understand like humans do. They predict what comes next in a sentence using math and probabilities. They don't have thoughts or feelings. They mimic human language but can make mistakes or write nonsense if not guided well.</p> <p>How you can use them: They're incredibly versatile. You can use them for answering questions, writing essays, coding help, and more. But you must be cautious because they can generate biased or false information if not used responsibly. </p> <p>In a nutshell, LLMs are like super-powered text generators trained on the internet's vast knowledge.</p> <p> </p> <p> VERIFY EVERTHING CHATBOTS TELL YOU! </p> <p> </p>"},{"location":"04_talk_to_computer/#prompt-writing","title":"Prompt Writing","text":"<p>LLM Chatbots are meant to be conversational. In general, you are asking the Chatbot questions (known as Prompts) and the Chatbot will respond with answers. </p> <p>It is a bit of an artform to get the Chatbot to provide answers with the specificity and format that you want. An entire field of study has sprung up, called Prompt Engineering, which seeks to find the magic words that will elicit the best (and technically correct) responses from the Chatbot. </p> <p> </p>"},{"location":"04_talk_to_computer/#prompt-priming","title":"Prompt Priming","text":"<p>Provide lots of organized details to help the Chatbot understand the question and what it's task is. This could include adding a backstory or context for why you are asking the question. Be very specific in terms of what you want from the Chatbot and how you want it. </p> <p>Zero-shot unconditioned prompts are likely to return the least specific responses. Responses are more likely to be useful when multiple specific output types are defined.</p> Types of Priming Example Zero (Shot) \"Write five examples of assessments for watershed health.\" Single \"Write five examples of assessments for watershed health. Here is one example: Geomorphology\" Multiple \"Write five examples of assessments for watershed health related to geomorphology, water quality, and species diversity.\" <p> </p>"},{"location":"04_talk_to_computer/#linked-prompts","title":"Linked Prompts","text":"<p>Responses to prompts may not return the exact details or information that you are after the first time. Follow-up by rephrasing your prompts more carefully and continuing with iterative prompting can build upon your priors.</p> <p>\"Chain prompting\" or \"Linked Prompting\" brings multiple prompts together.</p> Linked Prompting Examples Step 1: Priming \"I want you to act as an eminent hydrologist from CUASHI. Provide me with a list of the ten most important topics in hydrology over the last decade focused around research in the global south, working with indigenous communities, and traditional ecological knowledge systems.\" Step 2: Summarizing \"Based on the list you just created, summarize the most pressing financial challenges faced by indigenous communities in the Global South, versus indigenous communities in North America, in less than 50 words.\" Step 3: Try again with a web search \"Based on the results of web access, can you confirm the validity of the ten important topics and provide at least one reference to each.\" <p>Encouraging the Chatbot to do Better</p> <p>Chatbot responses can be missing information or just plain wrong. When this occurs, you can point out the mistake and ask the Chatbot to provide a more complete or better answer. Don't settle for poor responses!</p> <p> </p>"},{"location":"04_talk_to_computer/#role-playing","title":"Role Playing","text":"<p>Some people find that asking the Chatbot to adopt a persona will lead to better responses. </p> <p>\"I want you to act as ...\" will establish what type of conversation you are planning to have. </p> Types of Roles Project Manager Copywriter / Editor Paper Reviewer Teacher / Mentor / Advisor Student / Learner / Participant Software Engineer DevOps Engineer Linux Terminal Python Interpreter Web Browser <p> </p>"},{"location":"04_talk_to_computer/#prompting-chatbots-for-foss","title":"Prompting Chatbots for FOSS","text":""},{"location":"04_talk_to_computer/#provide-a-general-outline-for-a-data-management-plan","title":"Provide a general outline for a data management plan","text":"<p><pre><code>I am writing a grant proposal to the National Science Foundation. \nCould you please provide me a basic template for a data management plan (DMP) and \nplease provide url links to resources that can help me with NSF DMP requirements.\n</code></pre> </p>"},{"location":"04_talk_to_computer/#provide-a-step-by-step-recipe-to-create-and-serve-an-mkdocs-website-in-github","title":"Provide a step-by-step recipe to create and serve an mkdocs website in Github","text":"<p><pre><code>I would like to create a personal website using the MKdocs style \nand host it on Github pages.\n\nCould you please write me a step-by-step guide starting \nwith importing an existing github repository that has the mkdocs material.\n</code></pre> </p>"},{"location":"04_talk_to_computer/#write-shell-commands-and-shell-scripts","title":"Write shell commands and shell scripts","text":"<pre><code>I would like to create a linux shell script to automate the backup of my working directory. \nCould you please suggest a shell script that will copy my working directory \nin a different directory and compress the file into an archive. \nPlease name the file based on the current time and date. \n</code></pre>"},{"location":"04_talk_to_computer/#write-git-commands","title":"Write git commands","text":"<pre><code>Could you please provide me a step-by-step workflow for using git with github? \nI found a repository that I want to build on in Github. \nI would like to work on the material on my local machine and then save it back up to github. \nI would like to workflow to be for the linux command line. \n</code></pre>"},{"location":"04_talk_to_computer/#write-download-and-conda-commands","title":"Write download and conda commands","text":"<p><pre><code>I am writing a lot of scripts using python. I have heard that environment managers such as conda may be useful to me. \nI don't know anything about conda, so can you explain some things?\n1. Give me a high level overview of what environment managers are and what conda is specifically.\n2. Please create a step-by-step guide for downloading conda on my machine, and how to use conda to create custom environments. \n3. Please explain and give my steps to share my environment with colleagues.\n</code></pre> </p>"},{"location":"04_talk_to_computer/#write-docker-run-commands","title":"Write docker run commands","text":"<pre><code>I would like to run a docker container that consists of a jupyter notebook. \nCan you please suggest a docker run command that launches the jupyter notebook\nand mounts a volume of data in it. \n</code></pre>"},{"location":"04_talk_to_computer/#write-docker-files","title":"Write docker files","text":"<pre><code>I would like to create a docker image that consists of R studio and \nsome customized Rcode. Can you tell me the steps to 1. make a dockerfile and \nbuild the docker image; and 2. Upload the docker image to docker hub.\n</code></pre> ChatGPT  Awesome Lists <p>There is an ever changing meta-list of  Awesome lists curated around ChatGPT plugins and extensions.</p> <p> search: <code>chatgpt+awesome</code></p> <p>Check out lists around:</p> <p> ChatGPT Prompts</p> <p> ChatGPT Data Science Prompts</p> <p> API plugins, extensions, &amp; applications</p>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>In conjunction with for using CyVerse cyberinfrastructure, this Code of Conduct applies to all Event participants and their activities while using CyVerse resources and/or attending the Event.</p> <p>CyVerse is dedicated to providing professional computational research and educational experiences for all of our users, regardless of domain focus, academic status, educational level, gender/gender identity/expression, age, sexual orientation, mental or physical ability, physical appearance, body size, race, ethnicity, religion (or lack thereof), technology choices, dietary preferences, or any other personal characteristic.</p> <p>When using CyVerse or participating at an Event, we expect you to:</p> <ul> <li>Interact with others and use CyVerse professionally and ethically by     complying with our Policies.</li> <li>Constructively critize ideas and processes, not people.</li> <li>Follow the Golden Rule (treat others as you want to be treated) when     interacting online or in-person with collaborators, trainers, and     support staff.</li> <li>Comply with this Code in spirit as much as the letter, as it is     neither exhaustive nor complete in identifying any and all possible     unacceptable conduct.</li> </ul> <p>We do not tolerate harassment of other users or staff in any form (including, but not limited to, violent threats or language, derogatory language or jokes, doxing, insults, advocating for or encouraging any of these behaviors). Sexual language and imagery are not appropriate at any time (excludes Protected Health Information in compliance with HIPAA). Any user violating this Code may be expelled from the platform and the workshop at CyVerse's sole discretion without warning.</p> <p>To report a violation of this Code, directly message a trainer via Slack or email info@cyverse.org with the following information:</p> <ul> <li>Your contact information</li> <li>Names (real, username, pseudonyms) of any individuals involved, and     or witness(es) if any.</li> <li>Your account of what occurred and if the incident is ongoing. If     there is a publicly available record (a tweet, public chat log,     etc.), please include a link or attachment.</li> <li>Any additional information that may be helpful in resolving the     issue.</li> </ul>"},{"location":"glossary/","title":"Glossary &amp; Acronyms","text":"<p>A</p> <ul> <li>action: automate a workflow in the context of CI/CD, see GitHub Actions</li> <li>agile: development methodology     for organizing a team to complete tasks organized over short periods     called 'sprints'</li> <li>allocation: portion of a resource assigned to a particular     recipient, typical unit is a core or node hour</li> <li>Anaconda: open source data science platform.     Anaconda.com</li> <li>application: also called an 'app', a software designed to help     the user to perform specific task</li> <li>awesome: a curated set of lists that provide insight into     awesome software projects on GitHub</li> <li>AVU: Attribute-Value-Unit a components for iRODS     metadata.</li> </ul> <p>B</p> <ul> <li>beta: a software version which is not yet ready for     publication but is being tested</li> <li>bash: Bash is the GNU Project's shell, the Bourne-Again     Shell</li> <li>biocontainer: a community-driven project that provides the     infrastructure and basic guidelines to create, manage and distribute     bioinformatics packages (e.g conda) and containers (e.g docker,     singularity)</li> <li>bioconda: a channel for the conda package manager specializing     in bioinformatics software</li> </ul> <p>C</p> <ul> <li>CLI: the UNIX shell command line interface,     most typically BASH</li> <li>command: a set of instructions sent to the computer, typically     in a typed interface</li> <li>conda: an installation type of the Anaconda data science     platform. Command line application for managing packages and     environments</li> <li>container: virtualization of an operating system run within an     isolated user space</li> <li>Continuous Integration: (CI) is testing automation to check that     the application is not broken whenever new commits are integrated     into the main branch</li> <li>Continuous Delivery: (CD) is an extension of 'continuous     integration' to make sure that you can release new changes in a     sustainable way</li> <li>Continuous Deployment: a step further than 'continuous     delivery', every change that passes all stages of your production     pipeline is released</li> <li>Continuous Development: a process for iterative software     development and is an umbrella over several other processes     including 'continuous integration', 'continuous testing',     'continuous delivery' and 'continuous deployment'</li> <li>Continuous Testing: a process of testing and automating software     development.</li> <li>CRAN: The Comprehensive R Archive     Network</li> <li>CyVerse tool: Software program that is integrated into the back     end of the DE for use in DE apps</li> <li>CyVerse app: graphic interface of a tool made available for use     in the DE</li> </ul> <p>D</p> <ul> <li>Debian: a free OS, base of other     Linux distributions such as Ubuntu</li> <li>Development: the environment on your computer where you write     code</li> <li>DevOps Software *Dev*elopment and information techology     *Op*erations techniques for shortening the time to change software     in relation to CI/CD</li> <li>Discovery Environment (DE): a data science workbench for running     executable, interactive, and high throughput applications in     CyVerse DE</li> <li>distribution: abbreviated as 'distro', an operating system     made from a software collection based upon the Linux kernel</li> <li>Docker: Docker is an open source     software platform to create, deploy and manage virtualized     application containers on a common operating system (OS), with an     ecosystem of allied tools. A program that runs and handles     life-cycle of containers and images</li> <li>DockerHub: an official registry of docker containers, operated     by Docker. DockerHub</li> <li>DOI: a digital object identifier. A persistant identifier     number, managed by the doi.org</li> <li>Dockerfile: a text document that contains all the commands you     would normally execute manually in order to build a Docker image.     Docker can build images automatically by reading the instructions     from a Dockerfile</li> </ul> <p>E</p> <ul> <li>environment: software that includes operating system, database     system, specific tools for analysis</li> <li>entrypoint: In a Dockerfile, an ENTRYPOINT is an optional     definition for the first part of the command to be run</li> </ul> <p>F</p> <ul> <li>FOSS: (1) Free and Open Source Software, (2)     Foundational Open Science Skills - this class!</li> <li>function: a named section of a program that performs a specific     task</li> </ul> <p>G</p> <ul> <li>git: a version control system software</li> <li>gitter: a Github based messaging service that uses markdown     gitter.im</li> <li>GitHub: a website for hosting <code>git</code> repositories - owned by     Microsoft GitHub</li> <li>GitLab: a website for hosting <code>git</code> repositories     GitLab</li> <li>GitOps: using <code>git</code> framework as a means of deploying     infrastructure on cloud using Kubernetes</li> <li>GPU: graphic processing unit</li> <li>GUI: graphical user interface</li> </ul> <p>H</p> <ul> <li>hack: a quick job that produces what is needed, but not well</li> <li>HPC: High Performance Computer, for large syncronous computation</li> <li>HTC: High Throughput Computer, for many parallel tasks</li> </ul> <p>I</p> <ul> <li>IaaS: Infrastructure as a Service.     online services that provide APIs</li> <li>iCommands: command line application for     accessing iRODS Data Store</li> <li>IDE: integrated development environment, typically a graphical     interface for working with code language or packages</li> <li>instance: a single virtul machine</li> <li>image: self-contained, read-only 'snapshot' of your applications     and packages, with all their dependencies</li> <li>iRODS: an open source integrated Rule-Oriented Data Management     System, iRODS.org</li> </ul> <p>J</p> <ul> <li>Java: programming language, class-based, object-oriented</li> <li>JavaScript: programming language</li> <li>JSON: Java Script Object Notation, data interchange format that     uses human-readable text</li> <li>Jupyter(Hub,Lab,Notebooks): an IDE, originally the     iPythonNotebook, operates in the browser Project     Jupyter</li> </ul> <p>K</p> <ul> <li>kernel: central component of most operating systems (OS)</li> <li>Kubernetes: an open source container orchestration platform     created by Google Kubernetes is often     referred to as <code>K8s</code></li> </ul> <p>L</p> <ul> <li>lib: a UNIX library</li> <li>linux: open source Unix-like operating system</li> </ul> <p>M</p> <ul> <li>makefile: a file containing a set of directives used by a make     build automation tool</li> <li>markdown: a lightweight markup language with plain text     formatting syntax</li> <li>metadata:: data about data, useful for searching and querying</li> <li>multi-thread: a process which runs on more than one CPU or GPU     core at the same time</li> <li>master node: responsible for deciding what runs on all of the     cluster's nodes. Can include scheduling workloads, like     containerized applications, and managing the workloads' lifecycle,     scaling, and upgrades. The master also manages network and storage     resources for those workloads</li> <li>Mac OS X: Apple's popular desktop OS</li> </ul> <p>N</p> <ul> <li>node: a computer, typically 1 or 2 core (with many threads)     server in a cloud or HPC center</li> </ul> <p>O</p> <ul> <li>ontology: formal naming and structural hierarchy used to     describe data, also called a knowledge     graph</li> <li>organization: a group, in the context of GitHub a place where     developers contribute code to repositories</li> <li>Operating System (OS): software that manages computer hardware,     software resources, and provides common services for computer     programs</li> <li>Open Science Grid (OSG): national, distributed computing     partnership for data-intensive research     opensciencegrid.org</li> <li>ORCID: Open Researcher and Contributor ID     (ORCiD), a persistent digital identifier that     distinguishes you from every other researcher</li> </ul> <p>P</p> <ul> <li>PaaS: Platform as Service run     and manage applications in cloud without complexity of developing it     yourself</li> <li>package: an app designed for a particular langauge</li> <li>package manager: a collection of software tools that automates     the process of installing, upgrading, configuring, and removing     computer programs for a computer's operating system in a consistent     manner</li> <li>Production: environment where users access the final code after     all of the updates and testing</li> <li>Python: interpreted, high-level, general-purpose programming     language Python.org</li> </ul> <p>Q</p> <ul> <li>QUAY.io: private Docker registry QUAY.io</li> </ul> <p>R</p> <ul> <li>R: data science programming language R Project</li> <li>recipe file: a file with installation scripts used for building     software such as containers, e.g. Dockerfile</li> <li>registry: a storage and content delivery system, such as that     used by Docker</li> <li>remote desktop: a VM with a graphic user interface accessed via     a browser</li> <li>repo(sitory): a directory structure for hosting code and data</li> <li>RST: ReStructuredText, a markdown type file</li> <li>ReadTheDocs: a web service for rendering documentation (that     this website uses) readthedocs.org and     readthedocs.com</li> <li>root: the administrative user on a linux kernel - use your     powers wisely</li> </ul> <p>S</p> <ul> <li>SaaS: Software as a Service web     based platform for using software</li> <li>schema: a metadata standard for labeling, tagging or coding for     recording &amp; cataloging information or structuring descriptive     records. see schema.org</li> <li>scrum: daily set of tasks and evalautions as part of a sprint.</li> <li>shell: is a command line interface program that runs other     programs (may be complex, technical programs or very simple programs     such as making a directory). These simple, stand-alone programs are     called commands</li> <li>Singularity: a container software, used widely on HPC, created     by SyLabs</li> <li>SLACK: Searchable Log of All Conversation and Knowledge, a team     communication tool slack.com</li> <li>sprint: set period of time during which specific work has to be     completed and made ready for review</li> <li>Singularity def file: (definition file) recipe for building a     Singualrity container</li> <li>Stage: environment that is as similar to the production     environment as can be for final testing</li> </ul> <p>T</p> <ul> <li>tar: software utility for collecting many files into one archive     file, often referred to as a tarball</li> <li>tensor: algebraic object that describes a linear mapping from     one set of algebraic objects to another</li> <li>terminal: a windowed emulator for directly enterinc commands to     a computer</li> <li>thread: a CPU process or a series of linked messages in a     discussion board</li> <li>tool: In the context of CyVerse Discovery Environment, a Docker     Container</li> <li>TPU: tensor processing unit</li> <li>Travis: Travis-CI, a continuous     integration software</li> </ul> <p>U</p> <ul> <li>Ubuntu: most popular Linux OS     distribution, based on Debian</li> <li>UNIX: operating system</li> <li>user: the profile under which applications are started and run,     <code>root</code> is the most powerful system administrator</li> </ul> <p>V</p> <ul> <li>VICE: Visual Interactive Computing     Environment -     Cyverse Data Science Workbench</li> <li>virtual machine: is a software computer that, like a physical     computer, runs an operating system and applications</li> </ul> <p>W</p> <ul> <li>waterfall: software development broken into linear sequential     phases, similar to a Gantt chart</li> <li>webGL: JavaScript API for rendering interactive 2D and 3D     graphics within any compatible web browser without the use of     plug-ins</li> <li>Windows: Microsoft's most popular desktop OS</li> <li>workspace: (vs. repo)</li> <li>worker node: A cluster typically has one or more nodes, which     are the worker machines that run your containerized applications and     other workloads. Each node is managed from the master, which     receives updates on each node's self-reported status.</li> </ul> <p>X</p> <ul> <li>XML: Extensible Markup Language, data interchange format that     uses human-readable text</li> </ul> <p>Y</p> <ul> <li>YAML: YAML Ain't Markup Language, data interchange format that     uses human-readable text</li> </ul> <p>Z</p> <ul> <li>ZenHub: team collaboration solution built directly into GitHub     that uses kanban style boards</li> <li>Zenodo: general-purpose open-access repository developed under     the European OpenAIRE program and operated by CERN</li> <li>zip: a compressed file format</li> <li>zsh: Z-Shell, now the default shell on     new Mac OS X</li> </ul>"},{"location":"installation/","title":"Pre-FOSS Setup","text":"<p>Welcome to FOSS Online, we're happy you're here! To get you ready to hit the ground running, please set up the prerequisite accounts and software listed below before the course starts.</p>"},{"location":"installation/#account-creation","title":"Account Creation","text":"<p>We will be using several services that require you to create a user account.</p> Account Notes  GitHub GitHub will be used to store lecture materials and your own work. We will use GitHub Education and its free features for hands-on.  Slack We use the <code>CyVerse Learning</code>  Slack organization. You can use Slack in the browser, but the desktop app is usually less buggy.  HackMD We will use HackMD in order to facilitate daily discussions, questions and general notes. Link your HackMD using your GitHub account CyVerse We will introduce you to CyVerse which is a powerful cloud computer with large data storage. <p>Link to  HackMD</p> <p>https://hackmd.io/tLnlwjjTSoGG8U2yPHWQJw</p> Dual Monitors vs Side-by-Side <p>We strongly recommend you have dual monitors set-up while attending virtual FOSS Zoom lessons.</p> <p>We will be doing a lot of screen-sharing, and this will make your own interactive sessions less visible, or you will have to make them less than full screen.</p> <p>If you only have one monitor, make sure to exit full screen mode on Zoom and your browser, so you can view everything side-by-side</p>"},{"location":"installation/#required-software","title":"Required Software","text":"<p>You will need to have the following software installed on your personal computer:</p> Software Notes Web Browser  Chrome or  Firefox Text Editor  VS Code <p>Attention  Windows users</p> <p>Much of what we are going to be teaching is based on open-source software which operates on cloud and is incompatible within Windows OS. Don't worry</p> <p>Unix-based systems such as Linux  Ubuntu and  MacOS X, as many scientific tools require a Unix Operating System (OS). </p> <p>There are a number of software that allow Windows users to execute Unix commands, however we recommend the use of  Windows Subsystem for Linux (WSL) 2.0.</p> <p> VS Code is a Microsoft product and integrates seamlessly with Unix systems, we therefore strongly encourage you to install Code on your Windows OS.</p>"},{"location":"schedule/","title":"Weekly Schedule","text":"<p>Wednesdays @ 1100 - 1230 PDT / 1400 - 1530 EDT</p> <p>Format is Virtual, Zoom link will be emailed to enrolled attendees</p> <p>This schedule is tentative and subject to change</p>"},{"location":"schedule/#calendar","title":"Calendar","text":"Week Date Content Description Week 1 Sept. 4 Intro to Open Science Session Recording In the opening session we take in the big picture of what Open Science is and why. We will discuss how an open approach can be applied to scientific research. This is our least technical session. Week 2 Sept. 11 Data management Session Recording The foundation of any science endeavor is data. In this session we will dive deep into storing, sharing, and managing your datasets. We'll specifically cover data management plans (DMPs) and explain how licenses can allow other researchers to build on your work while ensuring credit is given. Week 3 Sept. 18 Project Management Session Recording Managing a productive, modern, digitally native, research group requires planning, governance, clear communication, and ethical codes of conduct. Week 4 Sept. 25 How to Talk to Computers Behind the veil of graphical point-and-click computing lies the command line, a more direct and powerful way to instruct your computer. In this session we will introduce you to the basics of the Unix command line (aka shell). This skill is not only useful for your personal computer, but also a necessity for cloud and HPC. We will also touch on LLM chatbots because they are changing the game of scientific computing very rapidly."}]}